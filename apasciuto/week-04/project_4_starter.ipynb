{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "URL = \"http://www.indeed.com/jobs?q=data+scientist+%2420%2C000&l=New+York&start=10\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "import bs4\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/AntonioPasciuto/anaconda/lib/python3.5/site-packages/bs4/__init__.py:181: UserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 184 of the file /Users/AntonioPasciuto/anaconda/lib/python3.5/runpy.py. To get rid of this warning, change code that looks like this:\n",
      "\n",
      " BeautifulSoup([your markup])\n",
      "\n",
      "to this:\n",
      "\n",
      " BeautifulSoup([your markup], \"lxml\")\n",
      "\n",
      "  markup_type=markup_type))\n"
     ]
    }
   ],
   "source": [
    "r = requests.get(URL)\n",
    "soup = BeautifulSoup(r.content)\n",
    "# Append to the full set of results\n",
    "results = soup.findAll('div', { \"class\" : \"result\" })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def extract_text(el):\n",
    "    if el:\n",
    "        return el.text.strip()\n",
    "    else:\n",
    "        return ''\n",
    "        \n",
    "\n",
    "def get_company_from_result(result):\n",
    "    return extract_text(result.find('span', {'class' : 'company'}))\n",
    "\n",
    "def get_location_from_result(result):\n",
    "    return  extract_text(result.find('span', {'class' : 'location'}))\n",
    "\n",
    "def get_summary_from_result(result):\n",
    "    return  extract_text(result.find('span', {'class' : 'summary'}))\n",
    "\n",
    "def get_title_from_result(result):\n",
    "    return result.find('a', {'data-tn-element' : 'jobTitle'}).text.strip()\n",
    "\n",
    "def get_salary_from_result(result):\n",
    "    salary_table = result.find('td', {'class' : 'snip'})\n",
    "    if salary_table:\n",
    "        snip = salary_table.find('nobr')\n",
    "        if snip:\n",
    "            return snip.text.strip()\n",
    "        \n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "YOUR_CITY = 'Atlanta'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/AntonioPasciuto/anaconda/lib/python3.5/site-packages/bs4/__init__.py:181: UserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 184 of the file /Users/AntonioPasciuto/anaconda/lib/python3.5/runpy.py. To get rid of this warning, change code that looks like this:\n",
      "\n",
      " BeautifulSoup([your markup])\n",
      "\n",
      "to this:\n",
      "\n",
      " BeautifulSoup([your markup], \"lxml\")\n",
      "\n",
      "  markup_type=markup_type))\n"
     ]
    }
   ],
   "source": [
    "url_template = \"http://www.indeed.com/jobs?q=data+scientist+%2420%2C000&l={}&start={}\"\n",
    "max_results_per_city = 100\n",
    "\n",
    "results = []\n",
    "\n",
    "for city in set(['New+York', 'Chicago', 'San+Francisco', 'Austin', 'Seattle', \n",
    "    'Los+Angeles', 'Philadelphia', 'Atlanta', 'Dallas', 'Pittsburgh', \n",
    "    'Portland', 'Phoenix', 'Denver', 'Houston', 'Miami', YOUR_CITY]):\n",
    "    for start in range(0, max_results_per_city, 10):\n",
    "        r = requests.get(url_template.format(city, start))\n",
    "        # Grab the results from the request (as above)\n",
    "        soup = BeautifulSoup(r.content)\n",
    "        # Append to the full set of results\n",
    "        results += soup.findAll('div', { \"class\" : \"result\" })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>city</th>\n",
       "      <th>company</th>\n",
       "      <th>salary</th>\n",
       "      <th>summary</th>\n",
       "      <th>title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>New+York</td>\n",
       "      <td>Predictive Science</td>\n",
       "      <td>None</td>\n",
       "      <td>This is a freelance data scientist position wh...</td>\n",
       "      <td>Data Scientist</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>New+York</td>\n",
       "      <td>Numeric Jobs</td>\n",
       "      <td>None</td>\n",
       "      <td>Manage multiple online &amp; offline data sources ...</td>\n",
       "      <td>Statistical Data Analyst</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>New+York</td>\n",
       "      <td>Pharma Resource Group Inc</td>\n",
       "      <td>None</td>\n",
       "      <td>Ability to draw conclusions from data, and to ...</td>\n",
       "      <td>Sr. Analytical Scientist</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>New+York</td>\n",
       "      <td>Susquehanna International Group</td>\n",
       "      <td>None</td>\n",
       "      <td>Your work will impact all aspects of the trade...</td>\n",
       "      <td>Quantitative Researcher - Machine Learning</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>New+York</td>\n",
       "      <td>University of Pennsylvania</td>\n",
       "      <td>None</td>\n",
       "      <td>Experience with data science a plus. Work with...</td>\n",
       "      <td>SENIOR DATA SCIENTIST</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       city                          company salary  \\\n",
       "0  New+York               Predictive Science   None   \n",
       "1  New+York                     Numeric Jobs   None   \n",
       "2  New+York        Pharma Resource Group Inc   None   \n",
       "3  New+York  Susquehanna International Group   None   \n",
       "4  New+York       University of Pennsylvania   None   \n",
       "\n",
       "                                             summary  \\\n",
       "0  This is a freelance data scientist position wh...   \n",
       "1  Manage multiple online & offline data sources ...   \n",
       "2  Ability to draw conclusions from data, and to ...   \n",
       "3  Your work will impact all aspects of the trade...   \n",
       "4  Experience with data science a plus. Work with...   \n",
       "\n",
       "                                        title  \n",
       "0                              Data Scientist  \n",
       "1                    Statistical Data Analyst  \n",
       "2                    Sr. Analytical Scientist  \n",
       "3  Quantitative Researcher - Machine Learning  \n",
       "4                       SENIOR DATA SCIENTIST  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rows = []\n",
    "for result in results:\n",
    "    if result:\n",
    "        row = {}\n",
    "        row['title'] = get_title_from_result(result)\n",
    "        row['company'] = get_company_from_result(result)\n",
    "        row['summary'] = get_summary_from_result(result)\n",
    "        row['salary'] = get_salary_from_result(result)\n",
    "        row['city'] = city\n",
    "        rows.append(row)\n",
    "\n",
    "import pandas as pd\n",
    "data = pd.DataFrame.from_records(rows)\n",
    "\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Filter to only the rows that have salary entries\n",
    "data = data[data.salary.notnull()]\n",
    "\n",
    "# Remove duplicates\n",
    "data = data.drop_duplicates()\n",
    "\n",
    "# Filter out salary entries referring to week, hour or month\n",
    "data = data[~(data.salary.astype('str').str.contains('hr'))]\n",
    "data = data[~(data.salary.astype('str').str.contains('hour'))]\n",
    "data = data[~(data.salary.astype('str').str.contains('week'))]\n",
    "data = data[~(data.salary.astype('str').str.contains('wk'))]\n",
    "data = data[~(data.salary.astype('str').str.contains('month'))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import re\n",
    "import numpy as np\n",
    "def extract_salary_average(salary_string):\n",
    "    regex = r'\\$([0-9]+,[0-9]+)'\n",
    "    matches = re.findall(regex, salary_string)\n",
    "    return np.mean([float(salary.replace(',', '')) for salary in matches ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data['parsed_salary'] = data['salary'].map(extract_salary_average)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
