{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import string\n",
    "from IPython.display import display, Image\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd \n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', None)\n",
    "\n",
    "import scipy\n",
    "from scipy.sparse import csr_matrix, hstack\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from keras.utils import np_utils\n",
    "from keras.optimizers import SGD\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
    "from sklearn.ensemble import RandomForestRegressor, ExtraTreesRegressor\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV\n",
    "from sklearn.metrics import classification_report, confusion_matrix, roc_curve, auc, f1_score\n",
    "from sklearn.feature_extraction import FeatureHasher\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.decomposition import TruncatedSVD, SparsePCA\n",
    "from sklearn.feature_selection import SelectPercentile, f_classif, chi2\n",
    "from sklearn.linear_model import LogisticRegression, SGDClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder, scale\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import log_loss\n",
    "\n",
    "import seaborn as sns\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as cm\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "grouptrain = pd.read_csv('db/group.csv').set_index('device_id')\n",
    "grouptest = pd.read_csv(\"input/gender_age_test.csv\").set_index('device_id')\n",
    "device = pd.read_csv('input/phone_brand_device_model.csv')\n",
    "# Get rid of duplicate device ids in phone\n",
    "device = device.drop_duplicates('device_id',keep='first').set_index('device_id')\n",
    "events = pd.read_csv(\"input/events.csv\", parse_dates=['timestamp'], index_col='event_id')\n",
    "appevents = pd.read_csv(\"input/app_events.csv\", usecols=['event_id', 'app_id', 'is_active'], dtype={'is_active':bool})\n",
    "applabels = pd.read_csv(\"input/app_labels.csv\")\n",
    "# label_categories = pd.read_csv(\"input/label_categories.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "device = device.rename(columns={'phone_brand' : 'device_brand'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "grouptrain['train_row'] = np.arange(len(grouptrain))\n",
    "grouptest['test_row'] = np.arange(len(grouptest))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "le_brand = LabelEncoder().fit(device.device_brand)\n",
    "device['brand'] = le_brand.transform(device['device_brand'])\n",
    "grouptrain[\"brand\"] = device[\"brand\"]\n",
    "grouptest['brand'] = device['brand']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "Xtrain_brand = csr_matrix((np.ones(len(grouptrain)), (grouptrain.train_row, grouptrain.brand)))\n",
    "Xtest_brand = csr_matrix((np.ones(len(grouptest)), (grouptest.test_row, grouptest.brand)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Brand features: train shape (74645, 131), test shape (112071, 131)\n"
     ]
    }
   ],
   "source": [
    "print('Brand features: train shape {}, test shape {}'.format(Xtrain_brand.shape, Xtest_brand.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model features: train shape (74645, 1667), test shape (112071, 1667)\n"
     ]
    }
   ],
   "source": [
    "mobile = device.device_brand.str.cat(device.device_model)\n",
    "le_model = LabelEncoder().fit(mobile)\n",
    "device['model'] = le_model.transform(mobile)\n",
    "grouptrain['model'] = device['model']\n",
    "grouptest['model'] = device['model']\n",
    "Xtrain_model = csr_matrix((np.ones(grouptrain.shape[0]), \n",
    "                       (grouptrain.train_row, grouptrain.model)))\n",
    "Xtest_model = csr_matrix((np.ones(grouptest.shape[0]), \n",
    "                       (grouptest.test_row, grouptest.model)))\n",
    "print('Model features: train shape {}, test shape {}'.format(Xtrain_model.shape, Xtest_model.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "le_app = LabelEncoder().fit(appevents.app_id)\n",
    "appevents['app'] = le_app.transform(appevents.app_id)\n",
    "n_appclasses = len(le_app.classes_)\n",
    "deviceapps = (appevents.merge(events[['device_id']], how='left',left_on='event_id',right_index=True)\n",
    "                       .groupby(['device_id','app'])['app'].agg(['size'])\n",
    "                       .merge(grouptrain[['train_row']], how='left', left_index=True, right_index=True)\n",
    "                       .merge(grouptest[['test_row']], how='left', left_index=True, right_index=True)\n",
    "                       .reset_index())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dapp = deviceapps.dropna(subset=['train_row'])\n",
    "Xtrain_app = csr_matrix((np.ones(dapp.shape[0]), (dapp.train_row, dapp.app)), \n",
    "                      shape=(grouptrain.shape[0],n_appclasses))\n",
    "dapp = deviceapps.dropna(subset=['test_row'])\n",
    "Xtest_app = csr_matrix((np.ones(dapp.shape[0]), (dapp.test_row, dapp.app)), \n",
    "                      shape=(grouptest.shape[0],n_appclasses))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "applabels = applabels.loc[applabels.app_id.isin(appevents.app_id.unique())]\n",
    "applabels['app'] = le_app.transform(applabels.app_id)\n",
    "le_labels = LabelEncoder().fit(applabels.label_id)\n",
    "applabels['label'] = le_labels.transform(applabels.label_id)\n",
    "n_labelsclasses = len(le_labels.classes_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>device_id</th>\n",
       "      <th>label</th>\n",
       "      <th>size</th>\n",
       "      <th>train_row</th>\n",
       "      <th>test_row</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-9222956879900151005</td>\n",
       "      <td>117</td>\n",
       "      <td>1</td>\n",
       "      <td>33721.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-9222956879900151005</td>\n",
       "      <td>120</td>\n",
       "      <td>1</td>\n",
       "      <td>33721.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-9222956879900151005</td>\n",
       "      <td>126</td>\n",
       "      <td>1</td>\n",
       "      <td>33721.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-9222956879900151005</td>\n",
       "      <td>138</td>\n",
       "      <td>2</td>\n",
       "      <td>33721.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-9222956879900151005</td>\n",
       "      <td>147</td>\n",
       "      <td>2</td>\n",
       "      <td>33721.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             device_id  label  size  train_row  test_row\n",
       "0 -9222956879900151005    117     1    33721.0       NaN\n",
       "1 -9222956879900151005    120     1    33721.0       NaN\n",
       "2 -9222956879900151005    126     1    33721.0       NaN\n",
       "3 -9222956879900151005    138     2    33721.0       NaN\n",
       "4 -9222956879900151005    147     2    33721.0       NaN"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "devicelabels = (deviceapps[['device_id','app']]\n",
    "                .merge(applabels[['app','label']])\n",
    "                .groupby(['device_id','label'])['app'].agg(['size'])\n",
    "                .merge(grouptrain[['train_row']], how='left', left_index=True, right_index=True)\n",
    "                .merge(grouptest[['test_row']], how='left', left_index=True, right_index=True)\n",
    "                .reset_index())\n",
    "devicelabels.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dapp = devicelabels.dropna(subset=['train_row'])\n",
    "Xtrain_label = csr_matrix((np.ones(dapp.shape[0]), (dapp.train_row, dapp.label)), \n",
    "                      shape=(grouptrain.shape[0],n_labelsclasses))\n",
    "dapp = devicelabels.dropna(subset=['test_row'])\n",
    "Xtest_label = csr_matrix((np.ones(dapp.shape[0]), (dapp.test_row, dapp.label)), \n",
    "                      shape=(grouptest.shape[0],n_labelsclasses))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All features: train shape (74645, 21527), test shape (112071, 21527)\n"
     ]
    }
   ],
   "source": [
    "Xtrain = hstack((Xtrain_brand, Xtrain_model, Xtrain_app, Xtrain_label), format='csr')\n",
    "Xtest =  hstack((Xtest_brand, Xtest_model, Xtest_app, Xtest_label), format='csr')\n",
    "print('All features: train shape {}, test shape {}'.format(Xtrain.shape, Xtest.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "le = LabelEncoder().fit(grouptrain.group)\n",
    "y = le.transform(grouptrain.group)\n",
    "n_classes = len(le.classes_)\n",
    "y_dummies = np_utils.to_categorical(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def batch_generator(X, y, batch_size, shuffle):\n",
    "    number_of_batches = np.ceil(X.shape[0]/batch_size)\n",
    "    counter = 0\n",
    "    sample_index = np.arange(X.shape[0])\n",
    "    if shuffle:\n",
    "        np.random.shuffle(sample_index)\n",
    "    while True:\n",
    "        batch_index = sample_index[batch_size*counter:batch_size*(counter+1)]\n",
    "        X_batch = X[batch_index,:].toarray()\n",
    "        y_batch = y[batch_index]\n",
    "        counter += 1\n",
    "        yield X_batch, y_batch\n",
    "        if (counter == number_of_batches):\n",
    "            if shuffle:\n",
    "                np.random.shuffle(sample_index)\n",
    "            counter = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def batch_generatorp(X, batch_size, shuffle):\n",
    "    number_of_batches = X.shape[0] / np.ceil(X.shape[0]/batch_size)\n",
    "    counter = 0\n",
    "    sample_index = np.arange(X.shape[0])\n",
    "    while True:\n",
    "        batch_index = sample_index[batch_size * counter:batch_size * (counter + 1)]\n",
    "        X_batch = X[batch_index, :].toarray()\n",
    "        counter += 1\n",
    "        yield X_batch\n",
    "        if (counter == number_of_batches):\n",
    "            counter = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def baseline_model():\n",
    "    model = Sequential()\n",
    "    model.add(Dense(50, input_dim=Xtrain.shape[1], init='normal', activation='tanh'))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(12, init='normal', activation='sigmoid'))\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='adadelta', metrics=['accuracy'])  #logloss\n",
    "    return model\n",
    "\n",
    "model=baseline_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/AntonioPasciuto/anaconda/lib/python3.5/site-packages/keras/engine/training.py:1527: UserWarning: Epoch comprised more than `samples_per_epoch` samples, which might affect learning results. Set `samples_per_epoch` correctly to avoid this warning.\n",
      "  warnings.warn('Epoch comprised more than '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "94s - loss: 2.2317 - acc: 0.2124 - val_loss: 2.2164 - val_acc: 0.2167\n",
      "Epoch 2/15\n",
      "90s - loss: 2.2300 - acc: 0.2135 - val_loss: 2.2178 - val_acc: 0.2173\n",
      "Epoch 3/15\n",
      "89s - loss: 2.2260 - acc: 0.2178 - val_loss: 2.2205 - val_acc: 0.2168\n",
      "Epoch 4/15\n",
      "87s - loss: 2.2241 - acc: 0.2156 - val_loss: 2.2221 - val_acc: 0.2148\n",
      "Epoch 5/15\n",
      "93s - loss: 2.2224 - acc: 0.2160 - val_loss: 2.2224 - val_acc: 0.2137\n",
      "Epoch 6/15\n",
      "95s - loss: 2.2160 - acc: 0.2186 - val_loss: 2.2237 - val_acc: 0.2131\n",
      "Epoch 7/15\n",
      "87s - loss: 2.2146 - acc: 0.2189 - val_loss: 2.2251 - val_acc: 0.2131\n",
      "Epoch 8/15\n",
      "86s - loss: 2.2163 - acc: 0.2193 - val_loss: 2.2256 - val_acc: 0.2131\n",
      "Epoch 9/15\n",
      "86s - loss: 2.2056 - acc: 0.2265 - val_loss: 2.2270 - val_acc: 0.2143\n",
      "Epoch 10/15\n",
      "92s - loss: 2.2081 - acc: 0.2240 - val_loss: 2.2284 - val_acc: 0.2104\n",
      "Epoch 11/15\n",
      "91s - loss: 2.2035 - acc: 0.2241 - val_loss: 2.2283 - val_acc: 0.2121\n",
      "Epoch 12/15\n",
      "89s - loss: 2.2006 - acc: 0.2267 - val_loss: 2.2304 - val_acc: 0.2115\n",
      "Epoch 13/15\n",
      "92s - loss: 2.1987 - acc: 0.2284 - val_loss: 2.2317 - val_acc: 0.2114\n",
      "Epoch 14/15\n",
      "86s - loss: 2.1939 - acc: 0.2288 - val_loss: 2.2314 - val_acc: 0.2111\n",
      "Epoch 15/15\n",
      "90s - loss: 2.1948 - acc: 0.2304 - val_loss: 2.2319 - val_acc: 0.2123\n"
     ]
    }
   ],
   "source": [
    "X_train, X_val, y_train, y_val = train_test_split(Xtrain, y_dummies, test_size=0.2, random_state=42)\n",
    "\n",
    "fit= model.fit_generator(generator=batch_generator(X_train, y_train, 32, True),\n",
    "                         nb_epoch=15,\n",
    "                         samples_per_epoch=70496,\n",
    "                         validation_data=(X_val.todense(), y_val), verbose=2\n",
    "                         )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logloss val 2.231851933004109\n"
     ]
    }
   ],
   "source": [
    "scores_val = model.predict_generator(generator=batch_generatorp(X_val, 32, False), val_samples=X_val.shape[0])\n",
    "scores = model.predict_generator(generator=batch_generatorp(Xtest, 32, False), val_samples=Xtest.shape[0])\n",
    "\n",
    "print('logloss val {}'.format(log_loss(y_val, scores_val)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pred = pd.DataFrame(scores, index = grouptest.index, columns=le.classes_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>F0-22</th>\n",
       "      <th>F23-26</th>\n",
       "      <th>F27-28</th>\n",
       "      <th>F29-32</th>\n",
       "      <th>F33-38</th>\n",
       "      <th>F39+</th>\n",
       "      <th>M0-22</th>\n",
       "      <th>M23-26</th>\n",
       "      <th>M27-28</th>\n",
       "      <th>M29-32</th>\n",
       "      <th>M33-38</th>\n",
       "      <th>M39+</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>device_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1002079943728939269</th>\n",
       "      <td>3.564054e-07</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>0.000008</td>\n",
       "      <td>0.000020</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>0.000020</td>\n",
       "      <td>0.000022</td>\n",
       "      <td>0.000080</td>\n",
       "      <td>0.000106</td>\n",
       "      <td>0.000245</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>-1547860181818787117</th>\n",
       "      <td>9.153597e-07</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>0.000008</td>\n",
       "      <td>0.000015</td>\n",
       "      <td>0.000022</td>\n",
       "      <td>0.000043</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>0.000029</td>\n",
       "      <td>0.000046</td>\n",
       "      <td>0.000108</td>\n",
       "      <td>0.000139</td>\n",
       "      <td>0.000073</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7374582448058474277</th>\n",
       "      <td>1.426640e-03</td>\n",
       "      <td>0.007812</td>\n",
       "      <td>0.009517</td>\n",
       "      <td>0.031844</td>\n",
       "      <td>0.033325</td>\n",
       "      <td>0.021419</td>\n",
       "      <td>0.001914</td>\n",
       "      <td>0.006517</td>\n",
       "      <td>0.010481</td>\n",
       "      <td>0.039864</td>\n",
       "      <td>0.039532</td>\n",
       "      <td>0.031826</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>-6220210354783429585</th>\n",
       "      <td>2.133572e-06</td>\n",
       "      <td>0.000010</td>\n",
       "      <td>0.000006</td>\n",
       "      <td>0.000006</td>\n",
       "      <td>0.000010</td>\n",
       "      <td>0.000037</td>\n",
       "      <td>0.000039</td>\n",
       "      <td>0.000200</td>\n",
       "      <td>0.000110</td>\n",
       "      <td>0.000128</td>\n",
       "      <td>0.000113</td>\n",
       "      <td>0.000105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>-5893464122623104785</th>\n",
       "      <td>4.581804e-03</td>\n",
       "      <td>0.013597</td>\n",
       "      <td>0.008271</td>\n",
       "      <td>0.012040</td>\n",
       "      <td>0.007646</td>\n",
       "      <td>0.008446</td>\n",
       "      <td>0.015809</td>\n",
       "      <td>0.037197</td>\n",
       "      <td>0.025206</td>\n",
       "      <td>0.031289</td>\n",
       "      <td>0.023275</td>\n",
       "      <td>0.018500</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             F0-22    F23-26    F27-28    F29-32    F33-38  \\\n",
       "device_id                                                                    \n",
       " 1002079943728939269  3.564054e-07  0.000001  0.000002  0.000003  0.000008   \n",
       "-1547860181818787117  9.153597e-07  0.000004  0.000008  0.000015  0.000022   \n",
       " 7374582448058474277  1.426640e-03  0.007812  0.009517  0.031844  0.033325   \n",
       "-6220210354783429585  2.133572e-06  0.000010  0.000006  0.000006  0.000010   \n",
       "-5893464122623104785  4.581804e-03  0.013597  0.008271  0.012040  0.007646   \n",
       "\n",
       "                          F39+     M0-22    M23-26    M27-28    M29-32  \\\n",
       "device_id                                                                \n",
       " 1002079943728939269  0.000020  0.000004  0.000020  0.000022  0.000080   \n",
       "-1547860181818787117  0.000043  0.000003  0.000029  0.000046  0.000108   \n",
       " 7374582448058474277  0.021419  0.001914  0.006517  0.010481  0.039864   \n",
       "-6220210354783429585  0.000037  0.000039  0.000200  0.000110  0.000128   \n",
       "-5893464122623104785  0.008446  0.015809  0.037197  0.025206  0.031289   \n",
       "\n",
       "                        M33-38      M39+  \n",
       "device_id                                 \n",
       " 1002079943728939269  0.000106  0.000245  \n",
       "-1547860181818787117  0.000139  0.000073  \n",
       " 7374582448058474277  0.039532  0.031826  \n",
       "-6220210354783429585  0.000113  0.000105  \n",
       "-5893464122623104785  0.023275  0.018500  "
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pred.to_csv('talkdatakeras.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
