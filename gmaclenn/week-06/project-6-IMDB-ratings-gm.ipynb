{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ![](https://ga-dash.s3.amazonaws.com/production/assets/logo-9f88ae6c9c3871690e33280fcf557f33.png) Project 6: APIs + Random Forests\n",
    "\n",
    "## Overview\n",
    "\n",
    "This week, we learned about ensemble methods, APIs, and natural language processing. Now we're going to put these skills to the test. You've been hired by Netflix to examine what factors lead to certain ratings for movies. Given that Netflix does not currently store this type of data, your boss has suggested that you collect ratings and reviews data from IMDB. Netflix is no stranger to machine learning, however:\n",
    "\n",
    "- Netflix uses random forests and decision trees to predict what types of movies an individual user may like.\n",
    "- Using unsupervised learning techniques, they are able to continually update suggestions, listings, and other features of it's user interface.\n",
    "- Netflix, however, hasn't focused on collecting data on the top movies of all time, and would like to add some of them to their offerings based on popularity and other factors.\n",
    "\n",
    "**Point:** Your boss isn't sure where to start on this project, so your task is to collect the data and construct a random forest to understand what factors contribute to ratings.\n",
    "\n",
    "\n",
    "## Project Summary\n",
    "Acquire data from IMDB, and use whatever metrics you can collect to predict whether it is a good movie.\n",
    "\n",
    "When you've finished your analysis, Netflix would like a report detailing your findings, with recommendations as to next steps.\n",
    "\n",
    "Here are some questions to keep in mind:\n",
    "\n",
    "- What factors are the most direct predictors of rating?\n",
    "- You can use rating as your target variable. But it's up to you whether to treat it as continuous, binary, or multiclass.\n",
    "\n",
    "**Goal**: Completed Jupyter notebook that includes modeling using a random forest and an blog post explaining your findings.\n",
    "\n",
    "---\n",
    "\n",
    "## Requirements\n",
    "This is deliberately open ended. There is no starter code. It's up to you how to acquire the data, store the data, and what features you want to use. \n",
    "\n",
    "We expect you to use a **tree-based model**, but the rest of the decisions are up to you. \n",
    "\n",
    "We will be looking for the following things:\n",
    " - A clear problem statement & description of the goals of your study to be included in the final report\n",
    " - Data from IMDB\n",
    " - Cleaned and refined data\n",
    " - Visualization. Plots that describe your data and evaluate your model.\n",
    " - Tree-based models (use any combination of ensemble techniques: random forests, bagging, boosting). \n",
    " - A blog post presenting the results of your findings as a report to Netflix, including:\n",
    "  - a problem statement,\n",
    "  - summary statistics of the various factors (e.g. year, number of ratings, etc.),\n",
    "  - your model,\n",
    "  - at least 2 graphics,\n",
    "  - and your recommendations for next steps!\n",
    "\n",
    "\n",
    "\n",
    "## Necessary Deliverables / Submission\n",
    "\n",
    "- Materials must be in a clearly labeled Jupyter notebook\n",
    "- Link to the blog post with your report in your Jupyter notebook\n",
    "- Materials must be submitted to GitHub by Thursday of Week 7 (July 21).\n",
    "\n",
    "---\n",
    "\n",
    "## Suggested Ways to Get Started\n",
    "\n",
    "- You can get data on the top 250 movies on IMDB using the [IMBDpie API](https://github.com/richardasaurus/imdb-pie) \n",
    "- If you need additional data, you can either research additional APIs, or scrape it yourself using BeautifulSoup\n",
    "- Read the docs for whatever technologies you use. Most of the time, there is a tutorial that you can follow, but not always, and learning to read documentation is crucial to your success!\n",
    "- Document **everything**.\n",
    "\n",
    "### Useful Resources\n",
    "\n",
    "[Documentation for BeautifulSoup](https://www.crummy.com/software/BeautifulSoup/bs4/doc/)\n",
    "\n",
    "---\n",
    "\n",
    "### Project Feedback + Evaluation\n",
    "\n",
    "[Attached here is a complete rubric for this project.](./project-06-rubric.md)\n",
    "\n",
    "Your instructors will score each of your technical requirements using the scale below:\n",
    "\n",
    "    Score | Expectations\n",
    "    ----- | ------------\n",
    "    **0** | _Incomplete._\n",
    "    **1** | _Does not meet expectations._\n",
    "    **2** | _Meets expectations, good job!_\n",
    "    **3** | _Exceeds expectations, you wonderful creature, you!_\n",
    "\n",
    " This will serve as a helpful overall gauge of whether you met the project goals, but __the more important scores are the individual ones__ above, which can help you identify where to focus your efforts for the next project!\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Use the IMDBpie API to pull data from IMDB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import requests\n",
    "import re\n",
    "from bs4 import BeautifulSoup\n",
    "from imdbpie import Imdb\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "\n",
    "#from IPython.core.interactiveshell import InteractiveShell\n",
    "# InteractiveShell.ast_node_interactivity = 'all'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "imdb = Imdb()\n",
    "imdb = Imdb(anonymize=True) # to proxy requests\n",
    "top_250 = pd.DataFrame(data=imdb.top_250())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>num_votes</th>\n",
       "      <th>rating</th>\n",
       "      <th>tconst</th>\n",
       "      <th>title</th>\n",
       "      <th>type</th>\n",
       "      <th>year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1756854</td>\n",
       "      <td>9.3</td>\n",
       "      <td>tt0111161</td>\n",
       "      <td>The Shawshank Redemption</td>\n",
       "      <td>feature</td>\n",
       "      <td>1994</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1199825</td>\n",
       "      <td>9.2</td>\n",
       "      <td>tt0068646</td>\n",
       "      <td>The Godfather</td>\n",
       "      <td>feature</td>\n",
       "      <td>1972</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>823982</td>\n",
       "      <td>9.0</td>\n",
       "      <td>tt0071562</td>\n",
       "      <td>The Godfather: Part II</td>\n",
       "      <td>feature</td>\n",
       "      <td>1974</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1739916</td>\n",
       "      <td>9.0</td>\n",
       "      <td>tt0468569</td>\n",
       "      <td>The Dark Knight</td>\n",
       "      <td>feature</td>\n",
       "      <td>2008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>471357</td>\n",
       "      <td>8.9</td>\n",
       "      <td>tt0050083</td>\n",
       "      <td>12 Angry Men</td>\n",
       "      <td>feature</td>\n",
       "      <td>1957</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   num_votes  rating     tconst                     title     type  year\n",
       "0    1756854     9.3  tt0111161  The Shawshank Redemption  feature  1994\n",
       "1    1199825     9.2  tt0068646             The Godfather  feature  1972\n",
       "2     823982     9.0  tt0071562    The Godfather: Part II  feature  1974\n",
       "3    1739916     9.0  tt0468569           The Dark Knight  feature  2008\n",
       "4     471357     8.9  tt0050083              12 Angry Men  feature  1957"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_250 = top_250.drop(['can_rate', 'image'], axis=1)\n",
    "top_250.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Pull in extra data for the top 250 movies from OMDB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# create a list of title id's for the top 250 IMDB movies\n",
    "top_250_t = top_250['tconst']\n",
    "t_const = top_250_t.tolist()\n",
    "\n",
    "# for each movie title pull extra data from OMDB API\n",
    "top_250_list = []\n",
    "for t in t_const:\n",
    "    payload = {'i':t,'plot':'short','r':'json', 'tomatoes':'True'} # modify the URL parameters here\n",
    "    URL = 'http://www.omdbapi.com/' # base URL\n",
    "    r = requests.get(URL, params=payload)\n",
    "    top_250_list.append(r.json())\n",
    "\n",
    "column_names = top_250_list[0].keys() # create column names variable\n",
    "\n",
    "# create a list of lists of the values from the api requests\n",
    "m_list = []\n",
    "for movie in top_250_list:\n",
    "    vals = movie.values()\n",
    "    m_list.append(vals)\n",
    "\n",
    "# create the top 250 dataframe\n",
    "top_250_df = pd.DataFrame(m_list, columns=column_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pull in Movie Reviews from IMDB using Requests and Beautiful Soup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "reviews = []\n",
    "for t in (t_const):\n",
    "    URL = ('http://www.imdb.com/title/' + t + '/reviews')\n",
    "    r2 = requests.get(URL).text\n",
    "    soup = BeautifulSoup(r2, 'html.parser')\n",
    "    page = soup.find_all('p')\n",
    "    foo = str(page)\n",
    "    regex = re.compile('[^a-zA-Z]')\n",
    "    new = regex.sub(' ', foo)\n",
    "    reviews.append(new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "reviews"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| Column  | Type  |  Description |\n",
    "|---------|-------|--------------|\n",
    "| Plot | Text | Description of plot |\n",
    "| Rated | Text | Movie rating |\n",
    "| Title | Text | Title name |\n",
    "| DVD| Date | Date movie came to DVD |\n",
    "| Genre | Text | CSV of genre types |\n",
    "| Language | Text | CSV of languages |\n",
    "| Country | Text | CSV of countries |\n",
    "| BoxOffice | Text | Gross $ values of box office sales |\n",
    "| Runtime | Text | Movie run time |\n",
    "| tomatoReviews | Int | # of rotten tomato reviews |\n",
    "| imdbID | Text | Unique movie ID |\n",
    "| Metascore | Int | Metacritic Scores |\n",
    "| Year | Int | Year movie was released|\n",
    "| Production | Text | Movie studio |\n",
    "| Reviews | Text | User reviews on IMDB |\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Converting the date columns to datetime format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# converts the listed columns to datetime formats\n",
    "top_250_df['Released'] = pd.to_datetime(top_250_df['Released'], format='%d %b %Y', errors='coerce')\n",
    "top_250_df['Year'] = pd.to_datetime(top_250_df['Year'], format='%Y', errors='coerce')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "top_250_df['Released'].groupby(top_250_df['Released'].dt.month).count().plot(kind='bar')\n",
    "plt.xlabel('Month')\n",
    "plt.ylabel('Count')\n",
    "plt.show()\n",
    "# df.groupby(df.date.dt.month).count().plot(kind=\"bar\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Dummy Variable columns: Production, Rated\n",
    "# Need to split by CSV: Genre, Actors, Director, Language, Country\n",
    "# Text columns that need Count Vectorizer: Plot, Writer, tomatoConsensus\n",
    "# Needs to be converted to Int: imdbVotes, tomatoUserReviews, BoxOffice, Runtime, tomatoReviews, Year\n",
    "# Target variable: imdbRating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "drop_columns = ['tomatoImage', 'Response', 'tomatoURL', 'Type', 'Website', 'Poster', \n",
    "                'tomatoMeter', 'tomatoUserRating', 'tomatoRotten', 'tomatoFresh', \n",
    "                'Awards', 'tomatoUserMeter', 'Metascore', 'imdbID', 'DVD', 'tomatoRating', \n",
    "                'Title', 'Language', 'Country', 'Writer', 'BoxOffice', 'Year']\n",
    "\n",
    "top_250_trimmed_df = top_250_df.drop(drop_columns, axis=1)\n",
    "top_250_trimmed_df.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convert continuous variables to int values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "top_250_trimmed_df['imdbVotes'] = [int(row.replace(\",\",\"\")) for row in top_250_trimmed_df['imdbVotes']]\n",
    "top_250_trimmed_df['tomatoReviews'] = [int(float(row.replace(\"N/A\", \"108.1\" ))) for row in top_250_trimmed_df['tomatoReviews']]\n",
    "top_250_trimmed_df['tomatoUserReviews'] = [int(float(row.replace(\"N/A\", \"1474214.07\"))) for row in top_250_trimmed_df['tomatoUserReviews']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we removed the N/A values, then we calculated the mean values for these below. Once we had the mean values for all the existing data points we re ran the conversion above. This time however we hard coded the mean values to act as a replacement value for missing values.\n",
    "\n",
    "* top_250_trimmed_df['tomatoUserReviews'].mean() = 1474214.07\n",
    "* top_250_trimmed_df['tomatoReviews'].mean() = 108.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "top_250_trimmed_df.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transform the Actors and Director columns so that they can be vectorized using CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# runs through the dataframe column and replaces the values\n",
    "# with actors names combined together\n",
    "for i, row in enumerate(top_250_trimmed_df['Actors']):\n",
    "    row_1 = row.replace(\", \",\",\")\n",
    "    row_2 = row_1.replace(\" \", \"\").lower()\n",
    "    top_250_trimmed_df.set_value(i,'Actors', row_2)\n",
    "    \n",
    "top_250_trimmed_df.Actors.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# runs through the dataframe column and replaces the values\n",
    "# with directors names combined together\n",
    "for i, row in enumerate(top_250_trimmed_df['Director']):\n",
    "    row_1 = row.replace(\", \",\",\")\n",
    "    row_2 = row_1.replace(\" \", \"\").lower()\n",
    "    top_250_trimmed_df.set_value(i,'Director', row_2)\n",
    "    \n",
    "top_250_trimmed_df.Director.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Use REGEX to combine production studios together."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "top_250_trimmed_df.groupby('Production').count()\n",
    "\n",
    "replacements = {\n",
    "    'Production': {\n",
    "        r'20th Century Fox Film Corporat': '20th Century Fox',\n",
    "        r'Buena Vista.*': 'Buena Vista Pictures',\n",
    "        r'Disney.*': 'Disney',\n",
    "        r'Dream[Ww]orks.*': 'DreamWorks',\n",
    "        r'Dream Works': 'DreamWorks',\n",
    "        r'Twentieth Century Fox.*': '20th Century Fox',\n",
    "        r'Warner Bros\\..*': 'Warner Bros.',\n",
    "        r'WARNER BROTHERS PICTURES' : 'Warner Bros.',\n",
    "        r'Warner Home Video': 'Warner Bros.',\n",
    "        r'Walt Disney': 'Disney',\n",
    "        r'Hollywood/Buena Vista Pictures': 'Buena Vista Pictures',\n",
    "        r'Sony Pictures.*': 'Sony Pictures',\n",
    "        r'The Weinstein Co.*': 'The Weinstein Co.',\n",
    "        r'UTV.*': 'UTV Motion Pictures',\n",
    "        r'United Artists.*': 'United Artists',\n",
    "        r'Universal.*': 'Universal Pictures',\n",
    "        r'Paramount.*': 'Paramount Pictures',\n",
    "        r'Orion.*': 'Orion Pictures',\n",
    "        r'Newmarket Film.*': 'Newmarket Film Group',\n",
    "        r'Miramax.*': 'Miramax Films',\n",
    "        r'20th Century 20th Century Fox': '20th Century Fox'\n",
    "    }\n",
    "}\n",
    "\n",
    "top_250_trimmed_df.replace(replacements, regex=True, inplace=True)\n",
    "\n",
    "top_250_trimmed_df.groupby('Production', sort=True).count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dummy_df = top_250_trimmed_df[['Rated', 'Production']]\n",
    "dummy_vars = pd.get_dummies(dummy_df)\n",
    "dummy_vars.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "top_250_cvec = top_250_trimmed_df[['tomatoConsensus', 'Actors', 'Director', 'Plot', 'Genre']]\n",
    "top_250_cvec.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Vectorize the columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cvec = CountVectorizer(stop_words='english')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Genre"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cvec.fit(top_250_cvec['Genre'])\n",
    "cvec_genres = pd.DataFrame(data=cvec.transform(top_250_cvec['Genre']).todense(),\n",
    "                          columns=cvec.get_feature_names())\n",
    "cvec_genres.head()\n",
    "word_counts_genres = cvec_genres.sum(axis=0)\n",
    "word_counts_genres.sort_values(ascending=False).head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### tomatoConsensus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model = cvec.fit(top_250_cvec['tomatoConsensus'])\n",
    "cvec_consensus = pd.DataFrame(data=cvec.transform(top_250_cvec['tomatoConsensus']).todense(), \n",
    "                                  columns=cvec.get_feature_names())\n",
    "                           \n",
    "cvec_consensus.head()\n",
    "word_counts_consensus = cvec_consensus.sum(axis=0)\n",
    "word_counts_consensus.sort_values(ascending=False).head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Actors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model = cvec.fit(top_250_cvec['Actors'])\n",
    "cvec_actors = pd.DataFrame(data=cvec.transform(top_250_cvec['Actors']).todense(), \n",
    "                                  columns=cvec.get_feature_names())\n",
    "                           \n",
    "cvec_actors.head()\n",
    "word_counts_actors = cvec_actors.sum(axis=0)\n",
    "word_counts_actors.sort_values(ascending=False).head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Director"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model = cvec.fit(top_250_cvec['Director'])\n",
    "cvec_director = pd.DataFrame(data=cvec.transform(top_250_cvec['Director']).todense(), \n",
    "                                  columns=cvec.get_feature_names())\n",
    "                           \n",
    "cvec_director.head()\n",
    "word_counts_director = cvec_director.sum(axis=0)\n",
    "word_counts_director.sort_values(ascending=False).head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model = cvec.fit(top_250_cvec['Plot'])\n",
    "cvec_plot = pd.DataFrame(data=cvec.transform(top_250_cvec['Plot']).todense(), \n",
    "                                  columns=cvec.get_feature_names())\n",
    "                           \n",
    "cvec_plot.head()\n",
    "word_counts_plot = cvec_plot.sum(axis=0)\n",
    "word_counts_plot.sort_values(ascending=False).head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model = cvec.fit(reviews)\n",
    "cvec_reviews = pd.DataFrame(data=cvec.transform(reviews).todense(), \n",
    "                                  columns=cvec.get_feature_names())\n",
    "                           \n",
    "cvec_reviews.head()\n",
    "word_counts_reviews = cvec_reviews.sum(axis=0)\n",
    "\n",
    "wcr = word_counts_reviews.sort_values(ascending=False).head(50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Took the top 50 words from reviews and filtered out the words that are either html artifacts (i.e. br, n, href, class) or generic english words that are not descriptive (i.e. movie, film, character). This approach is somewhat subjective in it's selection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "filter_reviews = ['best', 'great', 'life', 'good', 'love', 'action'] # somewhat subjective\n",
    "reviews_df = cvec_reviews[filter_reviews]\n",
    "reviews_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cvec_df = pd.concat([cvec_actors, cvec_consensus, cvec_director], axis=1)\n",
    "cvec_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "word_counts = cvec_df.sum(axis=0)\n",
    "wc = word_counts.sort_values(ascending=False).head(100)\n",
    "wc.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Combine the original DataFrame values with the reviews DataFrame to get our training and testing datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "master_training_df = pd.merge(top_250_trimmed_df, reviews_df, left_index=True, right_index=True)\n",
    "X = master_training_df.drop(['Plot','Rated','Production','Actors', 'tomatoConsensus', 'Director', 'Genre',\n",
    "                             'imdbRating', 'Runtime'], axis=1).astype(int)\n",
    "y = np.ravel(master_training_df[['imdbRating']])\n",
    "print X.dtypes\n",
    "y[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "np.ravel(X_train.index.tolist())\n",
    "reviews_df = pd.DataFrame(data=reviews)\n",
    "reviews_df_cvec = reviews_df.iloc[np.ravel(X_train.index.tolist())]\n",
    "reviews_df_cvec.columns = ['reviews']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model = cvec.fit(reviews_df_cvec['reviews'])\n",
    "cvec_reviews_training = pd.DataFrame(data=cvec.transform(reviews_df_cvec['reviews']).todense(), \n",
    "                                  columns=cvec.get_feature_names())\n",
    "                           \n",
    "cvec_reviews_training.head()\n",
    "word_counts_reviews_training = cvec_reviews_training.sum(axis=0)\n",
    "\n",
    "wcr = word_counts_reviews_training.sort_values(ascending=False).head(50)\n",
    "wcr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Normalize the values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "\n",
    "ss = StandardScaler()\n",
    "\n",
    "\n",
    "X_ss = ss.fit_transform(X, y)\n",
    "X_scaled = pd.DataFrame(data=X_ss, columns=X.columns)\n",
    "X_scaled.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.33, random_state=42)\n",
    "\n",
    "rf = RandomForestRegressor(n_estimators=100) # initialize\n",
    "rf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pd.DataFrame(data=rf.feature_importances_, index=X_train.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_pred = rf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pred_vs_act_df = pd.DataFrame(data=[y_pred,y_test], index=['predicted', 'Actual']).T\n",
    "pred_vs_act_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "\n",
    "print \"MAE:\", mae, \"MSE:\", mse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.scatter(y_pred,y_test)\n",
    "plt.plot([8,9.5],[8,9.5])\n",
    "plt.xlabel('Predicted IMDB Rating')\n",
    "plt.ylabel('Actual IMDB Rating')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
