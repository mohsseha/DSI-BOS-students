{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Selection Lab\n",
    "\n",
    "In this lab we will explore feature selection on the Titanic Dataset. First of all let's load a few things:\n",
    "\n",
    "- Standard packages\n",
    "- The training set from lab 2.3\n",
    "- The union we have saved in lab 2.3\n",
    "\n",
    "\n",
    "You can load the titanic data as follows:\n",
    "\n",
    "    psql -h dsi.c20gkj5cvu3l.us-east-1.rds.amazonaws.com -p 5432 -U dsi_student titanic\n",
    "    password: gastudents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sqlalchemy import create_engine\n",
    "engine = create_engine('postgresql://dsi_student:gastudents@dsi.c20gkj5cvu3l.us-east-1.rds.amazonaws.com/titanic')\n",
    "\n",
    "df = pd.read_sql('SELECT * FROM train', engine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.5924806 ,  0.        ,  0.        , ...,  1.        ,\n",
       "         1.        , -0.50244517],\n",
       "       [ 0.63878901,  1.        ,  0.        , ...,  0.        ,\n",
       "         0.        ,  0.78684529],\n",
       "       [-0.2846632 ,  0.        ,  0.        , ...,  1.        ,\n",
       "         0.        , -0.48885426],\n",
       "       ..., \n",
       "       [ 0.        ,  0.        ,  0.        , ...,  1.        ,\n",
       "         0.        , -0.17626324],\n",
       "       [-0.2846632 ,  1.        ,  0.        , ...,  0.        ,\n",
       "         1.        , -0.04438104],\n",
       "       [ 0.17706291,  0.        ,  0.        , ...,  0.        ,\n",
       "         1.        , -0.49237783]])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import gzip\n",
    "import dill\n",
    "\n",
    "\n",
    "with gzip.open('../../../2.3-lab/assets/datasets/union.dill.gz') as fin:\n",
    "    union = dill.load(fin)\n",
    "    \n",
    "X = df[[u'Pclass', u'Sex', u'Age', u'SibSp', u'Parch', u'Fare', u'Embarked']]\n",
    "y = df[u'Survived']\n",
    "\n",
    "X_transf = union.fit_transform(X)\n",
    "X_transf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['index', 'PassengerId', 'Survived', 'Pclass', 'Name', 'Sex', 'Age',\n",
       "       'SibSp', 'Parch', 'Ticket', 'Fare', 'Cabin', 'Embarked'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## 1 Column names\n",
    "\n",
    "Uh oh, we have lost the column names along the way! We need to manually add them:\n",
    "- age_pipe => 'scaled_age'\n",
    "- one_hot_pipe => 'Pclass_1', 'Pclass_2', 'Pclass_3', 'Embarked_C', 'Embarked_Q', 'Embarked_S'\n",
    "- gender_pipe => 'male'\n",
    "- fare_pipe => 'scaled_fare'\n",
    "\n",
    "Now we need to:\n",
    "\n",
    "1. Create a new pandas dataframe called `Xt` with the appropriate column names and fill it with the `X_transf` data.\n",
    "2. Notice that the current pipeline complitely discards the columns: u'SibSp', u'Parch'. Stack them as they are to the new dataframe\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "Xt = pd.DataFrame(X_transf, columns = [\n",
    "        'scaled_age', \n",
    "        'Pclass_1', 'Pclass_2', 'Pclass_3', 'Embarked_C', 'Embarked_Q', 'Embarked_S',\n",
    "        'male',\n",
    "        'scaled_fare'\n",
    "    ])\n",
    "Xt = pd.concat(objs = [Xt, X[[u'SibSp', u'Parch']]], axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Feature selection\n",
    "\n",
    "Let's use the `SelectKBest` method in scikit learn to see which are the top 5 features.\n",
    "\n",
    "- What are the top 5 features for `Xt`?\n",
    "\n",
    "=> store them in a variable called `kbest_columns`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pclass_1</th>\n",
       "      <th>Pclass_3</th>\n",
       "      <th>Embarked_C</th>\n",
       "      <th>male</th>\n",
       "      <th>scaled_fare</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.502445</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.786845</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.488854</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.420730</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.486337</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Pclass_1  Pclass_3  Embarked_C  male  scaled_fare\n",
       "0       0.0       1.0         0.0   1.0    -0.502445\n",
       "1       1.0       0.0         1.0   0.0     0.786845\n",
       "2       0.0       1.0         0.0   0.0    -0.488854\n",
       "3       1.0       0.0         0.0   0.0     0.420730\n",
       "4       0.0       1.0         0.0   1.0    -0.486337"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import feature_selection, linear_model\n",
    "\n",
    "selector = feature_selection.SelectKBest(feature_selection.f_classif, k = 5)\n",
    "selected_data = selector.fit_transform(Xt, y)\n",
    "\n",
    "kbest_columns = Xt.columns[selector.get_support()]\n",
    "kbest_columns\n",
    "\n",
    "Xtbest = pd.DataFrame(data = selected_data, columns = kbest_columns)\n",
    "Xtbest.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Recursive Feature Elimination\n",
    "\n",
    "`Scikit Learn` also offers recursive feature elimination as a class named `RFECV`. Use it in combination with a logistic regression model to see what features would be kept with this method.\n",
    "\n",
    "=> store them in a variable called `rfecv_columns`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on class RFECV in module sklearn.feature_selection.rfe:\n",
      "\n",
      "class RFECV(RFE, sklearn.base.MetaEstimatorMixin)\n",
      " |  Feature ranking with recursive feature elimination and cross-validated\n",
      " |  selection of the best number of features.\n",
      " |  \n",
      " |  Read more in the :ref:`User Guide <rfe>`.\n",
      " |  \n",
      " |  Parameters\n",
      " |  ----------\n",
      " |  estimator : object\n",
      " |      A supervised learning estimator with a `fit` method that updates a\n",
      " |      `coef_` attribute that holds the fitted parameters. Important features\n",
      " |      must correspond to high absolute values in the `coef_` array.\n",
      " |  \n",
      " |      For instance, this is the case for most supervised learning\n",
      " |      algorithms such as Support Vector Classifiers and Generalized\n",
      " |      Linear Models from the `svm` and `linear_model` modules.\n",
      " |  \n",
      " |  step : int or float, optional (default=1)\n",
      " |      If greater than or equal to 1, then `step` corresponds to the (integer)\n",
      " |      number of features to remove at each iteration.\n",
      " |      If within (0.0, 1.0), then `step` corresponds to the percentage\n",
      " |      (rounded down) of features to remove at each iteration.\n",
      " |  \n",
      " |  cv : int, cross-validation generator or an iterable, optional\n",
      " |      Determines the cross-validation splitting strategy.\n",
      " |      Possible inputs for cv are:\n",
      " |  \n",
      " |      - None, to use the default 3-fold cross-validation,\n",
      " |      - integer, to specify the number of folds.\n",
      " |      - An object to be used as a cross-validation generator.\n",
      " |      - An iterable yielding train/test splits.\n",
      " |  \n",
      " |      For integer/None inputs, if ``y`` is binary or multiclass,\n",
      " |      :class:`StratifiedKFold` used. If the estimator is a classifier\n",
      " |      or if ``y`` is neither binary nor multiclass, :class:`KFold` is used.\n",
      " |  \n",
      " |      Refer :ref:`User Guide <cross_validation>` for the various\n",
      " |      cross-validation strategies that can be used here.\n",
      " |  \n",
      " |  scoring : string, callable or None, optional, default: None\n",
      " |      A string (see model evaluation documentation) or\n",
      " |      a scorer callable object / function with signature\n",
      " |      ``scorer(estimator, X, y)``.\n",
      " |  \n",
      " |  estimator_params : dict\n",
      " |      Parameters for the external estimator.\n",
      " |      This attribute is deprecated as of version 0.16 and will be removed in\n",
      " |      0.18. Use estimator initialisation or set_params method instead.\n",
      " |  \n",
      " |  verbose : int, default=0\n",
      " |      Controls verbosity of output.\n",
      " |  \n",
      " |  Attributes\n",
      " |  ----------\n",
      " |  n_features_ : int\n",
      " |      The number of selected features with cross-validation.\n",
      " |  \n",
      " |  support_ : array of shape [n_features]\n",
      " |      The mask of selected features.\n",
      " |  \n",
      " |  ranking_ : array of shape [n_features]\n",
      " |      The feature ranking, such that `ranking_[i]`\n",
      " |      corresponds to the ranking\n",
      " |      position of the i-th feature.\n",
      " |      Selected (i.e., estimated best)\n",
      " |      features are assigned rank 1.\n",
      " |  \n",
      " |  grid_scores_ : array of shape [n_subsets_of_features]\n",
      " |      The cross-validation scores such that\n",
      " |      ``grid_scores_[i]`` corresponds to\n",
      " |      the CV score of the i-th subset of features.\n",
      " |  \n",
      " |  estimator_ : object\n",
      " |      The external estimator fit on the reduced dataset.\n",
      " |  \n",
      " |  Notes\n",
      " |  -----\n",
      " |  The size of ``grid_scores_`` is equal to ceil((n_features - 1) / step) + 1,\n",
      " |  where step is the number of features removed at each iteration.\n",
      " |  \n",
      " |  Examples\n",
      " |  --------\n",
      " |  The following example shows how to retrieve the a-priori not known 5\n",
      " |  informative features in the Friedman #1 dataset.\n",
      " |  \n",
      " |  >>> from sklearn.datasets import make_friedman1\n",
      " |  >>> from sklearn.feature_selection import RFECV\n",
      " |  >>> from sklearn.svm import SVR\n",
      " |  >>> X, y = make_friedman1(n_samples=50, n_features=10, random_state=0)\n",
      " |  >>> estimator = SVR(kernel=\"linear\")\n",
      " |  >>> selector = RFECV(estimator, step=1, cv=5)\n",
      " |  >>> selector = selector.fit(X, y)\n",
      " |  >>> selector.support_ # doctest: +NORMALIZE_WHITESPACE\n",
      " |  array([ True,  True,  True,  True,  True,\n",
      " |          False, False, False, False, False], dtype=bool)\n",
      " |  >>> selector.ranking_\n",
      " |  array([1, 1, 1, 1, 1, 6, 4, 3, 2, 5])\n",
      " |  \n",
      " |  References\n",
      " |  ----------\n",
      " |  \n",
      " |  .. [1] Guyon, I., Weston, J., Barnhill, S., & Vapnik, V., \"Gene selection\n",
      " |         for cancer classification using support vector machines\",\n",
      " |         Mach. Learn., 46(1-3), 389--422, 2002.\n",
      " |  \n",
      " |  Method resolution order:\n",
      " |      RFECV\n",
      " |      RFE\n",
      " |      sklearn.base.BaseEstimator\n",
      " |      sklearn.base.MetaEstimatorMixin\n",
      " |      sklearn.feature_selection.base.SelectorMixin\n",
      " |      abc.NewBase\n",
      " |      sklearn.base.TransformerMixin\n",
      " |      builtins.object\n",
      " |  \n",
      " |  Methods defined here:\n",
      " |  \n",
      " |  __init__(self, estimator, step=1, cv=None, scoring=None, estimator_params=None, verbose=0)\n",
      " |      Initialize self.  See help(type(self)) for accurate signature.\n",
      " |  \n",
      " |  fit(self, X, y)\n",
      " |      Fit the RFE model and automatically tune the number of selected\n",
      " |         features.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : {array-like, sparse matrix}, shape = [n_samples, n_features]\n",
      " |          Training vector, where `n_samples` is the number of samples and\n",
      " |          `n_features` is the total number of features.\n",
      " |      \n",
      " |      y : array-like, shape = [n_samples]\n",
      " |          Target values (integers for classification, real numbers for\n",
      " |          regression).\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data and other attributes defined here:\n",
      " |  \n",
      " |  __abstractmethods__ = frozenset()\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from RFE:\n",
      " |  \n",
      " |  decision_function(self, X)\n",
      " |      # lambda, but not partial, allows help() to work with update_wrapper\n",
      " |  \n",
      " |  predict(self, X)\n",
      " |      Reduce X to the selected features and then predict using the\n",
      " |         underlying estimator.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : array of shape [n_samples, n_features]\n",
      " |          The input samples.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      y : array of shape [n_samples]\n",
      " |          The predicted target values.\n",
      " |  \n",
      " |  predict_log_proba(self, X)\n",
      " |      # lambda, but not partial, allows help() to work with update_wrapper\n",
      " |  \n",
      " |  predict_proba(self, X)\n",
      " |      # lambda, but not partial, allows help() to work with update_wrapper\n",
      " |  \n",
      " |  score(self, X, y)\n",
      " |      Reduce X to the selected features and then return the score of the\n",
      " |         underlying estimator.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : array of shape [n_samples, n_features]\n",
      " |          The input samples.\n",
      " |      \n",
      " |      y : array of shape [n_samples]\n",
      " |          The target values.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from sklearn.base.BaseEstimator:\n",
      " |  \n",
      " |  __repr__(self)\n",
      " |      Return repr(self).\n",
      " |  \n",
      " |  get_params(self, deep=True)\n",
      " |      Get parameters for this estimator.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      deep: boolean, optional\n",
      " |          If True, will return the parameters for this estimator and\n",
      " |          contained subobjects that are estimators.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      params : mapping of string to any\n",
      " |          Parameter names mapped to their values.\n",
      " |  \n",
      " |  set_params(self, **params)\n",
      " |      Set the parameters of this estimator.\n",
      " |      \n",
      " |      The method works on simple estimators as well as on nested objects\n",
      " |      (such as pipelines). The former have parameters of the form\n",
      " |      ``<component>__<parameter>`` so that it's possible to update each\n",
      " |      component of a nested object.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      self\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors inherited from sklearn.base.BaseEstimator:\n",
      " |  \n",
      " |  __dict__\n",
      " |      dictionary for instance variables (if defined)\n",
      " |  \n",
      " |  __weakref__\n",
      " |      list of weak references to the object (if defined)\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from sklearn.feature_selection.base.SelectorMixin:\n",
      " |  \n",
      " |  get_support(self, indices=False)\n",
      " |      Get a mask, or integer index, of the features selected\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      indices : boolean (default False)\n",
      " |          If True, the return value will be an array of integers, rather\n",
      " |          than a boolean mask.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      support : array\n",
      " |          An index that selects the retained features from a feature vector.\n",
      " |          If `indices` is False, this is a boolean array of shape\n",
      " |          [# input features], in which an element is True iff its\n",
      " |          corresponding feature is selected for retention. If `indices` is\n",
      " |          True, this is an integer array of shape [# output features] whose\n",
      " |          values are indices into the input feature vector.\n",
      " |  \n",
      " |  inverse_transform(self, X)\n",
      " |      Reverse the transformation operation\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : array of shape [n_samples, n_selected_features]\n",
      " |          The input samples.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      X_r : array of shape [n_samples, n_original_features]\n",
      " |          `X` with columns of zeros inserted where features would have\n",
      " |          been removed by `transform`.\n",
      " |  \n",
      " |  transform(self, X)\n",
      " |      Reduce X to the selected features.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : array of shape [n_samples, n_features]\n",
      " |          The input samples.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      X_r : array of shape [n_samples, n_selected_features]\n",
      " |          The input samples with only the selected features.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from sklearn.base.TransformerMixin:\n",
      " |  \n",
      " |  fit_transform(self, X, y=None, **fit_params)\n",
      " |      Fit to data, then transform it.\n",
      " |      \n",
      " |      Fits transformer to X and y with optional parameters fit_params\n",
      " |      and returns a transformed version of X.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : numpy array of shape [n_samples, n_features]\n",
      " |          Training set.\n",
      " |      \n",
      " |      y : numpy array of shape [n_samples]\n",
      " |          Target values.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      X_new : numpy array of shape [n_samples, n_features_new]\n",
      " |          Transformed array.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(feature_selection.RFECV)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['scaled_age', 'Pclass_1', 'Pclass_2', 'Pclass_3', 'Embarked_C',\n",
       "       'Embarked_Q', 'male', 'SibSp'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "estimator = linear_model.LogisticRegression()\n",
    "selector = feature_selection.RFECV(estimator, step = 1, cv = 5)\n",
    "model = selector.fit(Xt, y)\n",
    "RFECV_best_columns = Xt.columns[model.get_support()]\n",
    "RFECV_best_columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Logistic regression coefficients\n",
    "\n",
    "Let's see if the Logistic Regression coefficients correspond.\n",
    "\n",
    "- Create a logistic regression model\n",
    "- Perform grid search over penalty type and C strength in order to find the best parameters\n",
    "- Sort the logistic regression coefficients by absolute value. Do the top 5 correspond to those above?\n",
    "> Answer: Not completely. That could be due to scaling\n",
    "\n",
    "=> choose which ones you would keep and store them in a variable called `lr_columns`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=None, error_score='raise',\n",
       "       estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False),\n",
       "       fit_params={}, iid=True, n_jobs=1,\n",
       "       param_grid={'C': [0.001, 0.01, 0.1, 1.0, 10.0, 100.0], 'penalty': ['l1', 'l2']},\n",
       "       pre_dispatch='2*n_jobs', refit=True, scoring=None, verbose=0)"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.grid_search import GridSearchCV\n",
    "\n",
    "# logreg = linear_model.LogisticRegression()\n",
    "\n",
    "# param_grid = {}\n",
    "# gs = GridSearchCV(estimator = logreg, scoring = 'f1_macro')\n",
    "\n",
    "# Sets up the model machinery based on GridSearchCV with attributes\n",
    "model = GridSearchCV(estimator = linear_model.LogisticRegression(), \n",
    "                     param_grid = {'C':[0.001, 0.01, 0.1, 1.0, 10.0, 100.0], \n",
    "                                   'penalty': ['l1', 'l2']}\n",
    "                    )\n",
    "# reshapes the model to fit the data to find the best \n",
    "model.fit(Xt, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.36507929  0.85346521  0.35192621 -0.55036096  0.35869727  0.25008366\n",
      "  -0.00280642 -1.87418976  0.22257075 -0.23090109 -0.01082475]]\n",
      "0.792368125701\n",
      "             coefficient\n",
      "male           -1.874190\n",
      "Pclass_3       -0.550361\n",
      "scaled_age     -0.365079\n",
      "SibSp          -0.230901\n",
      "Parch          -0.010825\n",
      "Embarked_S     -0.002806\n",
      "scaled_fare     0.222571\n",
      "Embarked_Q      0.250084\n",
      "Pclass_2        0.351926\n",
      "Embarked_C      0.358697\n",
      "Pclass_1        0.853465\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAlgAAAEfCAYAAACd07iVAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x118967550>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# best_estimator_ keeps the best\n",
    "print(model.best_estimator_.coef_)\n",
    "print(model.best_score_)\n",
    "\n",
    "coefficients_dataframe = pd.DataFrame(model.best_estimator_.coef_, columns = Xt.columns, index = ['coefficient']).T\n",
    "coefficients_dataframe.sort_values(by = 'coefficient', inplace = True)\n",
    "\n",
    "print(coefficients_dataframe)\n",
    "\n",
    "coefficients_dataframe.plot(kind = 'bar', figsize=(10,4))\n",
    "plt.xticks(rotation = 30)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Compare features sets\n",
    "\n",
    "Use the `best estimator` from question 4 on the 3 different feature sets:\n",
    "\n",
    "- `kbest_columns`\n",
    "- `rfecv_columns`\n",
    "- `lr_columns`\n",
    "- `all_columns`\n",
    "\n",
    "Questions:\n",
    "\n",
    "- Which scores the highest? (use cross_val_score)\n",
    "- Is the difference significant?\n",
    "> Answer: Not really\n",
    "- discuss in pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.79236812570145909"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.cross_validation import cross_val_score\n",
    "\n",
    "cross_val_score(model.best_estimator_.fit(Xtbest, y), Xt, y).mean()\n",
    "#cross_val_score(kbest, Xt, y).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bonus\n",
    "\n",
    "Use a bar chart to display the logistic regression coefficients. Start from the most negative on the left."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
