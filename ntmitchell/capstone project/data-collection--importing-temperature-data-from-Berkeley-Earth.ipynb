{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Defining functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Determining seasons by month\n",
    "def get_season (month, hemisphere = None):\n",
    "    northern_hemisphere_seasons = {1: 'Winter', 2: 'Winter', 3: 'Winter', 4: 'Spring', 5: 'Spring', 6: 'Spring', 7: 'Summer', 8: 'Summer', 9: 'Summer', 10: 'Fall', 11: 'Fall', 12: 'Fall'}\n",
    "    southern_hemisphere_seasons = {7: 'Winter', 8: 'Winter', 9: 'Winter', 10: 'Spring', 11: 'Spring', 12: 'Spring', 1: 'Summer', 2: 'Summer', 3: 'Summer', 4: 'Fall', 5: 'Fall', 6: 'Fall'}\n",
    "\n",
    "    if hemisphere.lower() == \"northern\":\n",
    "        season = northern_hemisphere_seasons[month]\n",
    "    elif hemisphere.lower() == \"southern\":\n",
    "        season = southern_hemisphere_seasons[month]\n",
    "    \n",
    "    return season"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Converting date fraction to datetime\n",
    "def convert_date_fraction_series_to_datetime(series = None):\n",
    "    \n",
    "    # Separate month decimal and year\n",
    "    month_decimal = np.mod(series, 1)\n",
    "    year = (series - month_decimal).astype(int)\n",
    "    \n",
    "    # Convert month decimal to month integer (1 = January, 2 = February, etc.)\n",
    "    month = np.round(12 * month_decimal + 0.5).astype(int)\n",
    "    \n",
    "    # Concatenate the values together into a string\n",
    "    date = year.astype(str) + \"-\" + month.astype(str) + \"-01\"\n",
    "    \n",
    "    # Convert the date strings into datetime values\n",
    "    series = pd.to_datetime(date, yearfirst = True)\n",
    "    \n",
    "    return series"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing weather station data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Import weather stations\n",
    "station_data = pd.read_csv(\"../datasets/capstone/downloaded data/berkeley_earth_stations--site_detail.txt\", \n",
    "                               delimiter = \"\\t\", \n",
    "                               skiprows =148, \n",
    "                               names = [\"Station ID\", \n",
    "                                        \"Station Name\", \n",
    "                                        \"Latitude\", \n",
    "                                        \"Longitude\", \n",
    "                                        \"Elevation (m)\", \n",
    "                                        \"Lat. Uncertainty\", \n",
    "                                        \"Long. Uncertainty\", \n",
    "                                        \"Elev. Uncertainty (m)\", \n",
    "                                        \"Country\", \n",
    "                                        \"State / Province Code\", \n",
    "                                        \"County\", \n",
    "                                        \"Time Zone\", \n",
    "                                        \"WMO ID\", \n",
    "                                        \"Coop ID\", \n",
    "                                        \"WBAN ID\", \n",
    "                                        \"ICAO ID\", \n",
    "                                        \"# of Relocations\", \n",
    "                                        \"# Suggested Relocations\", \n",
    "                                        \"# of Sources\", \n",
    "                                        \"Hash\"])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Formatting weather station data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Select only relevant columns\n",
    "station_data = station_data[[\"Station ID\", \"Station Name\", \"Latitude\", \"Longitude\", \"Elevation (m)\", \"Lat. Uncertainty\", \"Long. Uncertainty\", \"Elev. Uncertainty (m)\", \"Country\"]]\n",
    "\n",
    "# Convert values in numerical columns\n",
    "numeric_columns_in_stations_data = [\"Latitude\", \"Longitude\", \"Elevation (m)\", \"Lat. Uncertainty\", \"Long. Uncertainty\", \"Elev. Uncertainty (m)\"]\n",
    "station_data.loc[:, numeric_columns_in_stations_data] = station_data[numeric_columns_in_stations_data].apply(pd.to_numeric, errors = 'coerce')\n",
    "\n",
    "# Remove whitespace from non-numerical columns\n",
    "station_data.loc[:, \"Station Name\"] = station_data[\"Station Name\"].str.strip()\n",
    "station_data.loc[:, \"Country\"] = station_data[\"Country\"].str.strip()\n",
    "\n",
    "# Find when countries produce coffee\n",
    "coffee_harvest_schedule = pd.read_csv(\"../datasets/capstone/coffee harvest schedule.csv\", index_col = 0)\n",
    "\n",
    "# Concentrate on the stations in countries that produce coffee\n",
    "stations_in_coffee_producing_countries = station_data[station_data[\"Country\"].isin(coffee_harvest_schedule[\"Producing Country\"])]\n",
    "\n",
    "# Determing if most of each country's stations are in the northern or southern hemisphere\n",
    "hemisphere_dictionary = (station_data.groupby(by = \"Country\")[\"Latitude\"].mean() > 0).map({True: \"Northern\", False: \"Southern\"}).to_dict()\n",
    "\n",
    "# Arabica grows best in elevations 548 m – 1100 m for latitudes between 16° and 24°, or 1097 m – 1920 m for latitudes less that ±10°\n",
    "arabica_growing_conditions_criteria = (stations_in_coffee_producing_countries[\"Elevation (m)\"] >= 548) & (stations_in_coffee_producing_countries[\"Elevation (m)\"] <= 1100) & (stations_in_coffee_producing_countries[\"Latitude\"].abs() > 16) & (stations_in_coffee_producing_countries[\"Latitude\"].abs() <= 24)\n",
    "arabica_growing_conditions_criteria = arabica_growing_conditions_criteria | ((stations_in_coffee_producing_countries[\"Elevation (m)\"] >= 1097) & (stations_in_coffee_producing_countries[\"Elevation (m)\"] <= 1920) & (stations_in_coffee_producing_countries[\"Latitude\"].abs() <= 16))\n",
    "\n",
    "# Robusta grows best in elevations 0 m – 914 m in latitudes between ±10°\n",
    "robusta_growing_conditions_criteria = (stations_in_coffee_producing_countries[\"Elevation (m)\"] <= 914) & (stations_in_coffee_producing_countries[\"Latitude\"].abs() <= 10)\n",
    "\n",
    "# Select the stations in the ideal coffee growing regions\n",
    "stations_in_arabica_conditions = stations_in_coffee_producing_countries[arabica_growing_conditions_criteria][\"Station ID\"]\n",
    "stations_in_robusta_conditions = stations_in_coffee_producing_countries[robusta_growing_conditions_criteria][\"Station ID\"]\n",
    "\n",
    "stations_in_arabica_conditions_dictionary = dict.fromkeys(stations_in_arabica_conditions.values, True)\n",
    "stations_in_robusta_conditions_dictionary = dict.fromkeys(stations_in_robusta_conditions.values, True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing temperature data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Import raw temperature data from Berkeley Earth\n",
    "temperatures_for_all_stations = pd.read_csv(\"../datasets/capstone/downloaded data/berkeley_earth -- data.txt\", \n",
    "            delimiter = \"\\t\",  \n",
    "            skiprows = 111, \n",
    "            names = [\"Station ID\", \n",
    "                     \"Series Number\", \n",
    "                     \"Date\", \n",
    "                     \"Temperature (C)\", \n",
    "                     \"Uncertainty (C)\", \n",
    "                     \"Observations\", \n",
    "                     \"Time of Observation\"])\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Formatting temperature station data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "//anaconda/lib/python3.5/site-packages/ipykernel/__main__.py:22: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "//anaconda/lib/python3.5/site-packages/pandas/core/indexing.py:465: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self.obj[item] = s\n",
      "//anaconda/lib/python3.5/site-packages/ipykernel/__main__.py:49: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "//anaconda/lib/python3.5/site-packages/ipykernel/__main__.py:54: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    }
   ],
   "source": [
    "# Remove unnecessary labels\n",
    "temperatures_for_all_stations.drop(labels = [\"Series Number\", \"Uncertainty (C)\", \"Observations\", \"Time of Observation\"], axis = 1, inplace = True)\n",
    "\n",
    "# Select the temperature data for stations in coffee growing regions, and add country names\n",
    "temperatures_for_coffee_producing_countries = temperatures_for_all_stations[temperatures_for_all_stations[\"Station ID\"].isin(stations_in_coffee_producing_countries[\"Station ID\"])]\n",
    "temperatures_for_coffee_producing_countries = stations_in_coffee_producing_countries[[\"Station ID\", \"Country\"]].merge(temperatures_for_coffee_producing_countries, on = \"Station ID\")\n",
    "\n",
    "# Add columns indicating each station's hemisphere (for seasonality calculations later)\n",
    "temperatures_for_coffee_producing_countries[\"Hemisphere\"] = temperatures_for_coffee_producing_countries[\"Country\"].map(hemisphere_dictionary)\n",
    "\n",
    "# Designate stations in areas that grow arabica and robusta coffee\n",
    "temperatures_for_coffee_producing_countries[\"Arabica Production\"] = temperatures_for_coffee_producing_countries[\"Station ID\"].map(stations_in_arabica_conditions_dictionary)\n",
    "temperatures_for_coffee_producing_countries[\"Robusta Production\"] = temperatures_for_coffee_producing_countries[\"Station ID\"].map(stations_in_robusta_conditions_dictionary)\n",
    "temperatures_for_coffee_producing_countries = temperatures_for_coffee_producing_countries.fillna(False)\n",
    "\n",
    "# Keep the stations in areas that grow arabica or robusta coffee\n",
    "temperature_data = temperatures_for_coffee_producing_countries[\n",
    "    temperatures_for_coffee_producing_countries[\"Arabica Production\"]\n",
    "    | temperatures_for_coffee_producing_countries[\"Robusta Production\"]]\n",
    "\n",
    "# Drop the Station ID column since it's no longer needed\n",
    "temperature_data.drop(\"Station ID\", axis = 1, inplace = True)\n",
    "\n",
    "# Convert dates to datetime values\n",
    "temperature_data.loc[:, \"Date\"] = convert_date_fraction_series_to_datetime(temperature_data[\"Date\"])\n",
    "\n",
    "# Determine if an observation occurs within the harvest season for each country. \n",
    "# It's significantly easier to perform this before reindexing by time.\n",
    "# for country in temperature_data[\"Country\"].unique():\n",
    "#     for row in temperature_data[temperature_data[\"Country\"] == country].head().iterrows():\n",
    "#         crop = (\"Robusta\", \"Arabica\")[row[1][\"Arabica Production\"]]\n",
    "#         month = row[1][\"Date\"].month\n",
    "#         harvest_schedule_range = coffee_harvest_schedule[(coffee_harvest_schedule[\"Producing Country\"] == country) & (coffee_harvest_schedule[crop])][[\"Harvest Begins\", \"Harvest Ends\"]].values.tolist()\n",
    "#         if len(harvest_schedule_range) != 0:\n",
    "#             harvest_schedule = harvest_schedule_range[0]\n",
    "#             if harvest_schedule[0] < harvest_schedule[1]:\n",
    "#                 temperature_data.ix[row[0], \"Harvest Season\"] = (harvest_schedule[0] <= month <= harvest_schedule[1])\n",
    "#             elif harvest_schedule[0] > harvest_schedule[1]:\n",
    "#                 temperature_data.ix[row[0], \"Harvest Season\"] = (harvest_schedule[0] <= month + 12) and (month <= harvest_schedule[1])\n",
    "                \n",
    "# temperature_data[\"Harvest Season\"] = temperature_data[\"Harvest Season\"].map({True: True, False: False, np.NaN: False})\n",
    "                \n",
    "# Index by date\n",
    "temperature_data.set_index(\"Date\", inplace = True)\n",
    "# temperature_data = temperature_data.sort_index()\n",
    "\n",
    "\n",
    "# Add seasons columns\n",
    "temperature_data[\"Season\"] = temperature_data.index.month\n",
    "temperature_data.ix[temperature_data[\"Hemisphere\"] == \"Northern\", \"Season\"] = temperature_data[temperature_data[\"Hemisphere\"] == \"Northern\"][\"Season\"].apply(lambda x: get_season(x, hemisphere = \"Northern\"))\n",
    "temperature_data.ix[temperature_data[\"Hemisphere\"] == \"Southern\", \"Season\"] = temperature_data[temperature_data[\"Hemisphere\"] == \"Southern\"][\"Season\"].apply(lambda x: get_season(x, hemisphere = \"Southern\"))\n",
    "\n",
    "# Add frost likelihood\n",
    "temperature_data[\"Frost likelihood\"] = temperature_data[\"Temperature (C)\"] ** -2\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exporting final temperatures dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "temperature_data.to_csv(\"../datasets/capstone/temperature-in-coffee-growing-regions--from-berkeley-earth.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
