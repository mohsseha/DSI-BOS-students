{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Regression Metrics and Loss Functions\n",
    "\n",
    "We've seen two examples of _loss functions_ earlier in the week in the context of regularization.\n",
    "\n",
    "For a model of the form $y = f(x) + \\epsilon$ with predictions $\\hat{y}_i$ and true values $y_i$, we have:\n",
    "\n",
    "* The sum of squared errors:\n",
    "$$\\text{SSE} = \\sum_{i}{\\left(\\hat{y}_i - y_i \\right)^2}$$\n",
    "* A Regularlized version:\n",
    "If our model parameters are $\\theta_i$ and our regularization parameter is $\\alpha$, then the loss function took the form:\n",
    "$$\\text{L} = \\sum_{i}{\\left(\\hat{y}_i - y_i \\right)^2 + \\alpha \\theta_i}$$\n",
    "\n",
    "In this lesson we're going to dig deeper into loss functions and their applications. Different loss functions are useful in different scenarios and there are two very popular loss functions that are used in conjuction with regression. In this case they are sometimes referred to as _regression metrics_.\n",
    "\n",
    "The first is the _root mean squared error_ or _RMSE_ and it is the mean of the squared errors. If we have $n$ regression points and their predictions, the [RMSE](https://en.wikipedia.org/wiki/Root-mean-square_deviation) is:\n",
    "\n",
    "$$\\text{RMSE} = \\sqrt{\\frac{\\sum_{i}{\\left(\\hat{y}_i - y_i \\right)^2}}{n}}$$\n",
    "\n",
    "The second is the _mean absolute error_ or _MAE_, and it differs by use of an absolute value instead of a square. The [MAE](https://en.wikipedia.org/wiki/Average_absolute_deviation) is:\n",
    "\n",
    "$$\\text{MAE} = \\frac{\\sum_{i}{|\\hat{y}_i - y_i |}}{n}$$\n",
    "\n",
    "## Why have different regression metrics?\n",
    "\n",
    "You might be thinking, _what's all the fuss about_? It turns out that there are lots of good reasons to use different loss functions. We've seen one -- regularization -- and now we'll consider the effects of outliers on these two metrics.\n",
    "\n",
    "First let's try a very simplified statistics problem. Given a dataset, how can we summarize it with a single number? Do you know any ways?\n",
    "\n",
    "This is equivalent to fitting a constant model to the data. It turns out that the _mean_ minimizes the RMSE and the _median_ minimizes the MAE. By analogy, when fitting a model, MAE is more tolerant to outliers. In other words, the degree of error of an outlier has a large impact when using RMSE versus the MAE. Since the choice of loss function affects model fit, it's important to consider how you want errors to impact your models.\n",
    "\n",
    "**Summary**\n",
    "* Use MAE when how far off an error is makes little difference\n",
    "* Use RMSE when more extreme errors should have a large impact\n",
    "\n",
    "Finally, note that linear regressions with MAE instead of RMSE are called _least absolute deviation_ regressions rather than least squares regressions.\n",
    "\n",
    "### Bonus: Modes\n",
    "\n",
    "It turns out the _mode_ minimizes the sum:\n",
    "$$\\frac{\\sum_{i}{|\\hat{y}_i - y_i |^{0}}}{n}$$\n",
    "where $0^0=0$ and $x^0=1$ otherwise. Can you see why?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Guided practice\n",
    "\n",
    "Let's compute the RMSE and the MAE for a sample data set. Let's say we had a quadratic function that we fit a line to:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2, 1, 2, 5, 10]\n",
      "[-2, 0, 2, 4, 6]\n"
     ]
    }
   ],
   "source": [
    "xs = [-1, 0, 1, 2, 3]\n",
    "ys = [x*x + 1 for x in xs] # true values\n",
    "predictions = [2*x for x in xs]\n",
    "print (ys)\n",
    "print (predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First do the calculation by hand to see how large each term is\n",
    ".\n",
    "\n",
    ".\n",
    "\n",
    ".\n",
    "\n",
    ".\n",
    "\n",
    ".\n",
    "\n",
    ".\n",
    "\n",
    ".\n",
    "\n",
    ".\n",
    "\n",
    ".\n",
    "\n",
    ".\n",
    "\n",
    ".\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 2.6076809620810595\n",
      "MAE: 2.0\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "import math\n",
    "print (\"RMSE:\", math.sqrt(mean_squared_error(ys, predictions)))\n",
    "print (\"MAE:\", mean_absolute_error(ys, predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's add an outlier to the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 5.816642788871716\n",
      "MAE: 3.83333333333\n"
     ]
    }
   ],
   "source": [
    "xs.append(4)\n",
    "ys.append(17)\n",
    "predictions.append(30)\n",
    "\n",
    "print (\"RMSE:\", math.sqrt(mean_squared_error(ys, predictions)))\n",
    "print (\"MAE:\", mean_absolute_error(ys, predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice the impact of adding outliers to our data. The effect on the RMSE was large, a factor of 2.23, versus the impact on the MAE with a factor of 1.92. This behavior is expected because RMSE gives more weight to outliers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Indepedent Practice\n",
    "\n",
    "Let's explore two scenarios to obtain a better understanding of RMSE and MAE. First let's fit two models to the same set of data, the data above. To do the least mean absolute error we will use `statsmodels`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "% matplotlib inline\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "# Make the plots bigger\n",
    "plt.rcParams['figure.figsize'] = 10, 10\n",
    "import seaborn as sns\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn import linear_model\n",
    "import statsmodels.formula.api as smf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Let's add a few more points\n",
    "xs.append(2.5)\n",
    "ys.append(17)\n",
    "\n",
    "xs.append(1.5)\n",
    "ys.append(-6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "//anaconda/lib/python3.5/site-packages/scipy/stats/stats.py:1535: UserWarning: kurtosistest only valid for n>=20 ... continuing anyway, n=8\n",
      "  \"anyway, n=%i\" % int(n))\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>QuantReg Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>         <td>y</td>        <th>  Pseudo R-squared:  </th> <td>  0.3600</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>             <td>QuantReg</td>     <th>  Bandwidth:         </th> <td>   19.62</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>          <td>Least Squares</td>  <th>  Sparsity:          </th> <td>   28.42</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>          <td>Tue, 13 Dec 2016</td> <th>  No. Observations:  </th>  <td>     8</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>              <td>16:29:36</td>     <th>  Df Residuals:      </th>  <td>     6</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th> </th>                      <td> </td>        <th>  Df Model:          </th>  <td>     1</td> \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "      <td></td>         <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th> <th>[95.0% Conf. Int.]</th> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Intercept</th> <td>    1.0000</td> <td>    7.366</td> <td>    0.136</td> <td> 0.896</td> <td>  -17.023    19.023</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x</th>         <td>    3.0000</td> <td>    3.315</td> <td>    0.905</td> <td> 0.400</td> <td>   -5.111    11.111</td>\n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                         QuantReg Regression Results                          \n",
       "==============================================================================\n",
       "Dep. Variable:                      y   Pseudo R-squared:               0.3600\n",
       "Model:                       QuantReg   Bandwidth:                       19.62\n",
       "Method:                 Least Squares   Sparsity:                        28.42\n",
       "Date:                Tue, 13 Dec 2016   No. Observations:                    8\n",
       "Time:                        16:29:36   Df Residuals:                        6\n",
       "                                        Df Model:                            1\n",
       "==============================================================================\n",
       "                 coef    std err          t      P>|t|      [95.0% Conf. Int.]\n",
       "------------------------------------------------------------------------------\n",
       "Intercept      1.0000      7.366      0.136      0.896       -17.023    19.023\n",
       "x              3.0000      3.315      0.905      0.400        -5.111    11.111\n",
       "==============================================================================\n",
       "\"\"\""
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(np.array([xs, ys]).transpose(), columns=[\"x\", \"y\"])\n",
    "df.columns = [\"x\", \"y\"]\n",
    "mod = smf.quantreg('y ~ x', df)\n",
    "res = mod.fit(q=.5)\n",
    "res.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This generated a fit of $y = 3 x + 1$. Let's see what a linear regression yields."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "//anaconda/lib/python3.5/site-packages/scipy/stats/stats.py:1535: UserWarning: kurtosistest only valid for n>=20 ... continuing anyway, n=8\n",
      "  \"anyway, n=%i\" % int(n))\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>            <td>y</td>        <th>  R-squared:         </th> <td>   0.477</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.390</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   5.473</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Tue, 13 Dec 2016</td> <th>  Prob (F-statistic):</th>  <td>0.0579</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>16:29:36</td>     <th>  Log-Likelihood:    </th> <td> -24.966</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>     8</td>      <th>  AIC:               </th> <td>   53.93</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>     6</td>      <th>  BIC:               </th> <td>   54.09</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>     1</td>      <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "    <td></td>       <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th> <th>[95.0% Conf. Int.]</th> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>const</th> <td>    0.3844</td> <td>    3.282</td> <td>    0.117</td> <td> 0.911</td> <td>   -7.647     8.416</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x1</th>    <td>    3.4558</td> <td>    1.477</td> <td>    2.340</td> <td> 0.058</td> <td>   -0.159     7.070</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td> 2.698</td> <th>  Durbin-Watson:     </th> <td>   1.870</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.260</td> <th>  Jarque-Bera (JB):  </th> <td>   0.637</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td>-0.688</td> <th>  Prob(JB):          </th> <td>   0.727</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td> 3.141</td> <th>  Cond. No.          </th> <td>    3.64</td>\n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:                      y   R-squared:                       0.477\n",
       "Model:                            OLS   Adj. R-squared:                  0.390\n",
       "Method:                 Least Squares   F-statistic:                     5.473\n",
       "Date:                Tue, 13 Dec 2016   Prob (F-statistic):             0.0579\n",
       "Time:                        16:29:36   Log-Likelihood:                -24.966\n",
       "No. Observations:                   8   AIC:                             53.93\n",
       "Df Residuals:                       6   BIC:                             54.09\n",
       "Df Model:                           1                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "==============================================================================\n",
       "                 coef    std err          t      P>|t|      [95.0% Conf. Int.]\n",
       "------------------------------------------------------------------------------\n",
       "const          0.3844      3.282      0.117      0.911        -7.647     8.416\n",
       "x1             3.4558      1.477      2.340      0.058        -0.159     7.070\n",
       "==============================================================================\n",
       "Omnibus:                        2.698   Durbin-Watson:                   1.870\n",
       "Prob(Omnibus):                  0.260   Jarque-Bera (JB):                0.637\n",
       "Skew:                          -0.688   Prob(JB):                        0.727\n",
       "Kurtosis:                       3.141   Cond. No.                         3.64\n",
       "==============================================================================\n",
       "\n",
       "Warnings:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "\"\"\""
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import statsmodels.api as sm\n",
    "\n",
    "X = np.array(xs).transpose()\n",
    "X = sm.add_constant(X)\n",
    "# Fit and summarize OLS model\n",
    "mod = sm.OLS(ys, X)\n",
    "res = mod.fit()\n",
    "res.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This yielded a fit of $y = 3.4558 x + 0.3844$.\n",
    "\n",
    "### Exercise\n",
    "\n",
    "Plot the data with both functions. Which do you think fits the data better?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "x and y must have same first dimension",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-37-b7230f764961>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscatter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mys\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mxs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m//anaconda/lib/python3.5/site-packages/matplotlib/pyplot.py\u001b[0m in \u001b[0;36mplot\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m   3159\u001b[0m         \u001b[0max\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhold\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhold\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3160\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3161\u001b[0;31m         \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0max\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3162\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3163\u001b[0m         \u001b[0max\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhold\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwashold\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m//anaconda/lib/python3.5/site-packages/matplotlib/__init__.py\u001b[0m in \u001b[0;36minner\u001b[0;34m(ax, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1817\u001b[0m                     warnings.warn(msg % (label_namer, func.__name__),\n\u001b[1;32m   1818\u001b[0m                                   RuntimeWarning, stacklevel=2)\n\u001b[0;32m-> 1819\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0max\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1820\u001b[0m         \u001b[0mpre_doc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minner\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__doc__\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1821\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mpre_doc\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m//anaconda/lib/python3.5/site-packages/matplotlib/axes/_axes.py\u001b[0m in \u001b[0;36mplot\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1380\u001b[0m         \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcbook\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnormalize_kwargs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_alias_map\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1381\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1382\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mline\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_lines\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1383\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_line\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mline\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1384\u001b[0m             \u001b[0mlines\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mline\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m//anaconda/lib/python3.5/site-packages/matplotlib/axes/_base.py\u001b[0m in \u001b[0;36m_grab_next_args\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    379\u001b[0m                 \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    380\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mremaining\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 381\u001b[0;31m                 \u001b[0;32mfor\u001b[0m \u001b[0mseg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_plot_args\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mremaining\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    382\u001b[0m                     \u001b[0;32myield\u001b[0m \u001b[0mseg\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    383\u001b[0m                 \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m//anaconda/lib/python3.5/site-packages/matplotlib/axes/_base.py\u001b[0m in \u001b[0;36m_plot_args\u001b[0;34m(self, tup, kwargs)\u001b[0m\n\u001b[1;32m    357\u001b[0m             \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mindex_of\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtup\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    358\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 359\u001b[0;31m         \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_xy_from_xy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    360\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    361\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcommand\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'plot'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m//anaconda/lib/python3.5/site-packages/matplotlib/axes/_base.py\u001b[0m in \u001b[0;36m_xy_from_xy\u001b[0;34m(self, x, y)\u001b[0m\n\u001b[1;32m    217\u001b[0m         \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_check_1d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    218\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 219\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"x and y must have same first dimension\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    220\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m2\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    221\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"x and y can be no greater than 2-D\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: x and y must have same first dimension"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAecAAAFVCAYAAADVDycqAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAFCY/wb6n/uF4RZe3QAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x11d1976a0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "f1 = lambda x: 3.4558*x + 0.3844\n",
    "\n",
    "\n",
    "plt.scatter(xs, ys)\n",
    "plt.plot(xs, map(f1, xs))\n",
    "\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, let's explore another scenario. Linear regression has five major assumptions, one of which is called _constant variance_ or _homoscedasticity_. It means that the errors are distributed with the same variance about the best fit line regardless of the value of the independent variables.\n",
    "\n",
    "For example, a persistant level of background noise can cause regression metrics to be poorly estimated. Let's take a look."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAeQAAAFVCAYAAAA+OJwpAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nABjg/wM4YXLzjJyYNQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x11d12d080>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import random\n",
    "from scipy.stats import norm\n",
    "# Generate some data\n",
    "xs = list(np.arange(0, 10, 0.1))\n",
    "ys = [2*x + norm.pdf(0, 1) for x in xs]\n",
    "# Add random background noise\n",
    "xs2 = [10 * random.random() for i in range(20)]\n",
    "ys2 = [20 * random.random() for i in range(20)]\n",
    "\n",
    "# Plot the data sets\n",
    "plt.scatter(xs, ys, color='b')\n",
    "plt.scatter(xs2, ys2, color='r')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Combine the data\n",
    "xs.extend(xs2)\n",
    "ys.extend(ys2)\n",
    "df = pd.DataFrame(np.array([xs, ys]).transpose(), columns=['x', 'y'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.0, 0.10000000000000001, 0.20000000000000001, 0.30000000000000004, 0.40000000000000002]\n",
      "[0.24197072451914337, 0.44197072451914338, 0.64197072451914339, 0.84197072451914345, 1.0419707245191434]\n",
      "     x         y\n",
      "0  0.0  0.241971\n",
      "1  0.1  0.441971\n",
      "2  0.2  0.641971\n",
      "3  0.3  0.841971\n",
      "4  0.4  1.041971\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>QuantReg Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>         <td>y</td>        <th>  Pseudo R-squared:  </th> <td>  0.7849</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>             <td>QuantReg</td>     <th>  Bandwidth:         </th> <td>1.934e-07</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>          <td>Least Squares</td>  <th>  Sparsity:          </th> <td>5.067e-07</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>          <td>Tue, 13 Dec 2016</td> <th>  No. Observations:  </th>  <td>   120</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>              <td>16:54:27</td>     <th>  Df Residuals:      </th>  <td>   118</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th> </th>                      <td> </td>        <th>  Df Model:          </th>  <td>     1</td>  \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "      <td></td>         <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th> <th>[95.0% Conf. Int.]</th> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Intercept</th> <td>    0.2420</td> <td> 4.55e-08</td> <td> 5.32e+06</td> <td> 0.000</td> <td>    0.242     0.242</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x</th>         <td>    2.0000</td> <td> 8.04e-09</td> <td> 2.49e+08</td> <td> 0.000</td> <td>    2.000     2.000</td>\n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                         QuantReg Regression Results                          \n",
       "==============================================================================\n",
       "Dep. Variable:                      y   Pseudo R-squared:               0.7849\n",
       "Model:                       QuantReg   Bandwidth:                   1.934e-07\n",
       "Method:                 Least Squares   Sparsity:                    5.067e-07\n",
       "Date:                Tue, 13 Dec 2016   No. Observations:                  120\n",
       "Time:                        16:54:27   Df Residuals:                      118\n",
       "                                        Df Model:                            1\n",
       "==============================================================================\n",
       "                 coef    std err          t      P>|t|      [95.0% Conf. Int.]\n",
       "------------------------------------------------------------------------------\n",
       "Intercept      0.2420   4.55e-08   5.32e+06      0.000         0.242     0.242\n",
       "x              2.0000   8.04e-09   2.49e+08      0.000         2.000     2.000\n",
       "==============================================================================\n",
       "\"\"\""
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fit a line to the data\n",
    "# Compute the RMSE and the MAE\n",
    "# Plot the regression line\n",
    "\n",
    "print(xs[0:5])\n",
    "print(ys[0:5])\n",
    "print(df[0:5])\n",
    "\n",
    "mod = smf.quantreg('y ~ x', df)\n",
    "res = mod.fit(q=.5)\n",
    "res.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 3.1496083594313915\n",
      "MAE: 1.06478249521\n"
     ]
    }
   ],
   "source": [
    "f = lambda x: 0.242 + 2 * x\n",
    "df['model_y'] = df['x'].apply(f)\n",
    "\n",
    "print (\"RMSE:\", math.sqrt(mean_squared_error(df['y'], df['model_y'])))\n",
    "print (\"MAE:\", mean_absolute_error(df['y'], df['model_y']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Now try a MAE regression with statsmodels and plot it.\n",
    "# You should see a much better fit.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Plot the data and the two fits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
