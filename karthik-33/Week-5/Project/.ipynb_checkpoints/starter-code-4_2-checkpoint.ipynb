{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Selection Lab\n",
    "\n",
    "In this lab we will explore feature selection on the Titanic Dataset. First of all let's load a few things:\n",
    "\n",
    "- Standard packages\n",
    "- The training set from lab 2.3\n",
    "- The union we have saved in lab 2.3\n",
    "\n",
    "\n",
    "You can load the titanic data as follows:\n",
    "\n",
    "    psql -h dsi.c20gkj5cvu3l.us-east-1.rds.amazonaws.com -p 5432 -U dsi_student titanic\n",
    "    password: gastudents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'3.5.2 |Anaconda custom (64-bit)| (default, Jul  5 2016, 11:41:13) [MSC v.1900 64 bit (AMD64)]'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sys\n",
    "sys.version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sqlalchemy import create_engine\n",
    "engine = create_engine('postgresql://dsi_student:gastudents@dsi.c20gkj5cvu3l.us-east-1.rds.amazonaws.com/titanic')\n",
    "\n",
    "df = pd.read_sql('SELECT * FROM train', engine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.5924806 ,  0.        ,  0.        , ...,  1.        ,\n",
       "         1.        , -0.50244517],\n",
       "       [ 0.63878901,  1.        ,  0.        , ...,  0.        ,\n",
       "         0.        ,  0.78684529],\n",
       "       [-0.2846632 ,  0.        ,  0.        , ...,  1.        ,\n",
       "         0.        , -0.48885426],\n",
       "       ..., \n",
       "       [ 0.        ,  0.        ,  0.        , ...,  1.        ,\n",
       "         0.        , -0.17626324],\n",
       "       [-0.2846632 ,  1.        ,  0.        , ...,  0.        ,\n",
       "         1.        , -0.04438104],\n",
       "       [ 0.17706291,  0.        ,  0.        , ...,  0.        ,\n",
       "         1.        , -0.49237783]])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import gzip\n",
    "import dill\n",
    "\n",
    "with gzip.open('union.dill.gz') as fin:\n",
    "    union = dill.load(fin)\n",
    "    \n",
    "X = df[[u'Pclass', u'Sex', u'Age', u'SibSp', u'Parch', u'Fare', u'Embarked']]\n",
    "y = df[u'Survived']\n",
    "\n",
    "X_transf = union.fit_transform(X)\n",
    "X_transf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## 1 Column names\n",
    "\n",
    "Uh oh, we have lost the column names along the way! We need to manually add them:\n",
    "- age_pipe => 'scaled_age'\n",
    "- one_hot_pipe => 'Pclass_1', 'Pclass_2', 'Pclass_3', 'Embarked_C', 'Embarked_Q', 'Embarked_S'\n",
    "- gender_pipe => 'male'\n",
    "- fare_pipe => 'scaled_fare'\n",
    "\n",
    "Now we need to:\n",
    "\n",
    "1. Create a new pandas dataframe called `Xt` with the appropriate column names and fill it with the `X_transf` data.\n",
    "2. Notice that the current pipeline complitely discards the columns: u'SibSp', u'Parch'. Stack them as they are to the new dataframe\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>scaled_age</th>\n",
       "      <th>Pclass_1</th>\n",
       "      <th>Pclass_2</th>\n",
       "      <th>Pclass_3</th>\n",
       "      <th>Embarked_C</th>\n",
       "      <th>Embarked_Q</th>\n",
       "      <th>Embarked_S</th>\n",
       "      <th>male</th>\n",
       "      <th>scaled_fare</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.592481</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.502445</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.638789</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.786845</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.284663</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.488854</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.407926</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.420730</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.407926</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.486337</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   scaled_age  Pclass_1  Pclass_2  Pclass_3  Embarked_C  Embarked_Q  \\\n",
       "0   -0.592481       0.0       0.0       1.0         0.0         0.0   \n",
       "1    0.638789       1.0       0.0       0.0         1.0         0.0   \n",
       "2   -0.284663       0.0       0.0       1.0         0.0         0.0   \n",
       "3    0.407926       1.0       0.0       0.0         0.0         0.0   \n",
       "4    0.407926       0.0       0.0       1.0         0.0         0.0   \n",
       "\n",
       "   Embarked_S  male  scaled_fare  SibSp  Parch  \n",
       "0         1.0   1.0    -0.502445      1      0  \n",
       "1         0.0   0.0     0.786845      1      0  \n",
       "2         1.0   0.0    -0.488854      0      0  \n",
       "3         1.0   0.0     0.420730      1      0  \n",
       "4         1.0   1.0    -0.486337      0      0  "
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "col = ['scaled_age', 'Pclass_1', 'Pclass_2', 'Pclass_3', 'Embarked_C', 'Embarked_Q', 'Embarked_S', \n",
    "       'male', 'scaled_fare']\n",
    "Xt= pd.DataFrame(data = X_transf, columns = col)\n",
    "Xt[\"SibSp\"] = X[\"SibSp\"]\n",
    "Xt[\"Parch\"] = X[\"Parch\"]\n",
    "Xt.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Feature selection\n",
    "\n",
    "Let's use the `SelectKBest` method in scikit learn to see which are the top 5 features.\n",
    "\n",
    "- What are the top 5 features for `Xt`?\n",
    "\n",
    "=> store them in a variable called `kbest_columns`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import SelectKBest\n",
    "model1 = SelectKBest(k = 5)\n",
    "fit1 = model1.fit(Xt, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "col = model1.get_support()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pclass_1</th>\n",
       "      <th>Pclass_3</th>\n",
       "      <th>Embarked_C</th>\n",
       "      <th>male</th>\n",
       "      <th>scaled_fare</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.502445</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.786845</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.488854</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.420730</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.486337</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Pclass_1  Pclass_3  Embarked_C  male  scaled_fare\n",
       "0       0.0       1.0         0.0   1.0    -0.502445\n",
       "1       1.0       0.0         1.0   0.0     0.786845\n",
       "2       0.0       1.0         0.0   0.0    -0.488854\n",
       "3       1.0       0.0         0.0   0.0     0.420730\n",
       "4       0.0       1.0         0.0   1.0    -0.486337"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Xt_KBest = model1.transform(Xt)\n",
    "df_KBest = pd.DataFrame(data = Xt_KBest, columns = Xt.columns[col])\n",
    "df_KBest.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Recursive Feature Elimination\n",
    "\n",
    "`Scikit Learn` also offers recursive feature elimination as a class named `RFECV`. Use it in combination with a logistic regression model to see what features would be kept with this method.\n",
    "\n",
    "=> store them in a variable called `rfecv_columns`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RFECV(cv=5,\n",
       "   estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False),\n",
       "   estimator_params=None, scoring=None, step=1, verbose=0)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_selection import RFECV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "estimator = LogisticRegression()\n",
    "selector = RFECV(estimator, cv = 5)\n",
    "selector.fit(Xt, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "col = selector.get_support()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>scaled_age</th>\n",
       "      <th>Pclass_1</th>\n",
       "      <th>Pclass_2</th>\n",
       "      <th>Pclass_3</th>\n",
       "      <th>Embarked_C</th>\n",
       "      <th>Embarked_Q</th>\n",
       "      <th>male</th>\n",
       "      <th>SibSp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.592481</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.638789</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.284663</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.407926</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.407926</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   scaled_age  Pclass_1  Pclass_2  Pclass_3  Embarked_C  Embarked_Q  male  \\\n",
       "0   -0.592481       0.0       0.0       1.0         0.0         0.0   1.0   \n",
       "1    0.638789       1.0       0.0       0.0         1.0         0.0   0.0   \n",
       "2   -0.284663       0.0       0.0       1.0         0.0         0.0   0.0   \n",
       "3    0.407926       1.0       0.0       0.0         0.0         0.0   0.0   \n",
       "4    0.407926       0.0       0.0       1.0         0.0         0.0   1.0   \n",
       "\n",
       "   SibSp  \n",
       "0    1.0  \n",
       "1    1.0  \n",
       "2    0.0  \n",
       "3    1.0  \n",
       "4    0.0  "
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Xt_RFECV = selector.transform(Xt)\n",
    "df_RFECV = pd.DataFrame(data = Xt_RFECV, columns = Xt.columns[col])\n",
    "df_RFECV.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Logistic regression coefficients\n",
    "\n",
    "Let's see if the Logistic Regression coefficients correspond.\n",
    "\n",
    "- Create a logistic regression model\n",
    "- Perform grid search over penalty type and C strength in order to find the best parameters\n",
    "- Sort the logistic regression coefficients by absolute value. Do the top 5 correspond to those above?\n",
    "> Answer: Not completely. That could be due to scaling\n",
    "\n",
    "=> choose which ones you would keep and store them in a variable called `lr_columns`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.grid_search import GridSearchCV\n",
    "model = LogisticRegression()\n",
    "params = {\"C\": [0.0001, 0.001, 0.01, 0.1, 1, 10, 100, 1000, 10000], \"penalty\": [\"l1\", \"l2\"]}\n",
    "selector = GridSearchCV(model, params, cv = 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model_fit = selector.fit(Xt, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.36507929,  0.85346521,  0.35192621, -0.55036096,  0.35869727,\n",
       "         0.25008366, -0.00280642, -1.87418976,  0.22257075, -0.23090109,\n",
       "        -0.01082475]])"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best = selector.best_estimator_\n",
    "best.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>variable</th>\n",
       "      <th>value</th>\n",
       "      <th>Abs value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>male</td>\n",
       "      <td>-1.874190</td>\n",
       "      <td>1.874190</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Pclass_1</td>\n",
       "      <td>0.853465</td>\n",
       "      <td>0.853465</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Pclass_3</td>\n",
       "      <td>-0.550361</td>\n",
       "      <td>0.550361</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>scaled_age</td>\n",
       "      <td>-0.365079</td>\n",
       "      <td>0.365079</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Embarked_C</td>\n",
       "      <td>0.358697</td>\n",
       "      <td>0.358697</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     variable     value  Abs value\n",
       "7        male -1.874190   1.874190\n",
       "1    Pclass_1  0.853465   0.853465\n",
       "3    Pclass_3 -0.550361   0.550361\n",
       "0  scaled_age -0.365079   0.365079\n",
       "4  Embarked_C  0.358697   0.358697"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2 = pd.melt(pd.DataFrame(data = best.coef_, columns = Xt.columns))\n",
    "df2[\"Abs value\"] = df2[\"value\"].abs()\n",
    "df2.sort_values(\"Abs value\", inplace = True, ascending = False)\n",
    "lr_columns = df2[\"variable\"][:5].tolist()\n",
    "df2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=0.1, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>male</th>\n",
       "      <th>Pclass_1</th>\n",
       "      <th>Pclass_3</th>\n",
       "      <th>scaled_age</th>\n",
       "      <th>Embarked_C</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.592481</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.638789</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.284663</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.407926</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.407926</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   male  Pclass_1  Pclass_3  scaled_age  Embarked_C\n",
       "0   1.0       0.0       1.0   -0.592481         0.0\n",
       "1   0.0       1.0       0.0    0.638789         1.0\n",
       "2   0.0       0.0       1.0   -0.284663         0.0\n",
       "3   0.0       1.0       0.0    0.407926         0.0\n",
       "4   1.0       0.0       1.0    0.407926         0.0"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_lr = Xt[lr_columns]\n",
    "df_lr.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Compare features sets\n",
    "\n",
    "Use the `best estimator` from question 4 on the 3 different feature sets:\n",
    "\n",
    "- `kbest_columns`\n",
    "- `rfecv_columns`\n",
    "- `lr_columns`\n",
    "- `all_columns`\n",
    "\n",
    "Questions:\n",
    "\n",
    "- Which scores the highest? (use cross_val_score)\n",
    "- Is the difference significant?\n",
    "> Answer: Not really\n",
    "- discuss in pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.cross_validation import cross_val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KBest:  [ 0.7150838   0.7877095   0.79213483  0.75280899  0.79096045]\n",
      "RFECV:  [ 0.73743017  0.79888268  0.81460674  0.79213483  0.82485876]\n",
      "LR_5:  [ 0.72067039  0.79888268  0.80337079  0.76966292  0.82485876]\n",
      "LR_all:  [ 0.74860335  0.80446927  0.82022472  0.7752809   0.84180791]\n"
     ]
    }
   ],
   "source": [
    "print(\"KBest: \", cross_val_score(best, df_KBest, y, cv = 5))\n",
    "print(\"RFECV: \", cross_val_score(best, df_RFECV, y, cv = 5))\n",
    "print(\"LR_5: \", cross_val_score(best, df_lr, y, cv = 5))\n",
    "print(\"LR_all: \", cross_val_score(best, Xt, y, cv = 5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bonus\n",
    "\n",
    "Use a bar chart to display the logistic regression coefficients. Start from the most negative on the left."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAgwAAAHECAYAAABV1XJLAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n6twg/gAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1784dcac4a8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df2.sort_values(\"value\", inplace = True, ascending = True)\n",
    "df2.plot(kind = \"bar\", x = \"variable\", y = \"value\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
