{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Support Vector Machines Lab"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this lab we will explore several datasets with SVMs. The assets folder contains several datasets (in order of complexity):\n",
    "\n",
    "1. Breast cancer\n",
    "- Spambase\n",
    "- Car evaluation\n",
    "- Mushroom\n",
    "\n",
    "For each of these a `.names` file is provided with details on the origin of data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 1: Breast Cancer\n",
    "\n",
    "\n",
    "\n",
    "## 1.a: Load the Data\n",
    "Use `pandas.read_csv` to load the data and assess the following:\n",
    "- Are there any missing values? (how are they encoded? do we impute them?)\n",
    "- Are the features categorical or numerical?\n",
    "- Are the values normalized?\n",
    "- How many classes are there in the target?\n",
    "\n",
    "Perform what's necessary to get to a point where you have a feature matrix `X` and a target vector `y`, both with only numerical entries.\n",
    "\n",
    "C:/Users/Pat.NOAGALLERY/Documents/data_sources/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 699 entries, 0 to 698\n",
      "Data columns (total 11 columns):\n",
      "Sample_code_number             699 non-null int64\n",
      "Clump_Thickness                699 non-null int64\n",
      "Uniformity_of_Cell_Size        699 non-null int64\n",
      "Uniformity_of_Cell_Shape       699 non-null int64\n",
      "Marginal_Adhesion              699 non-null int64\n",
      "Single_Epithelial_Cell_Size    699 non-null int64\n",
      "Bare_Nuclei                    699 non-null object\n",
      "Bland_Chromatin                699 non-null int64\n",
      "Normal_Nucleoli                699 non-null int64\n",
      "Mitoses                        699 non-null int64\n",
      "Class                          699 non-null int64\n",
      "dtypes: int64(10), object(1)\n",
      "memory usage: 60.1+ KB\n"
     ]
    }
   ],
   "source": [
    "bc = pd.read_csv(\"C:/Users/Pat.NOAGALLERY/Documents/data_sources/breast_cancer.csv\")\n",
    "bc.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sample_code_number</th>\n",
       "      <th>Clump_Thickness</th>\n",
       "      <th>Uniformity_of_Cell_Size</th>\n",
       "      <th>Uniformity_of_Cell_Shape</th>\n",
       "      <th>Marginal_Adhesion</th>\n",
       "      <th>Single_Epithelial_Cell_Size</th>\n",
       "      <th>Bland_Chromatin</th>\n",
       "      <th>Normal_Nucleoli</th>\n",
       "      <th>Mitoses</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>6.990000e+02</td>\n",
       "      <td>699.000000</td>\n",
       "      <td>699.000000</td>\n",
       "      <td>699.000000</td>\n",
       "      <td>699.000000</td>\n",
       "      <td>699.000000</td>\n",
       "      <td>699.000000</td>\n",
       "      <td>699.000000</td>\n",
       "      <td>699.000000</td>\n",
       "      <td>699.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>1.071704e+06</td>\n",
       "      <td>4.417740</td>\n",
       "      <td>3.134478</td>\n",
       "      <td>3.207439</td>\n",
       "      <td>2.806867</td>\n",
       "      <td>3.216023</td>\n",
       "      <td>3.437768</td>\n",
       "      <td>2.866953</td>\n",
       "      <td>1.589413</td>\n",
       "      <td>2.689557</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>6.170957e+05</td>\n",
       "      <td>2.815741</td>\n",
       "      <td>3.051459</td>\n",
       "      <td>2.971913</td>\n",
       "      <td>2.855379</td>\n",
       "      <td>2.214300</td>\n",
       "      <td>2.438364</td>\n",
       "      <td>3.053634</td>\n",
       "      <td>1.715078</td>\n",
       "      <td>0.951273</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>6.163400e+04</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>8.706885e+05</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>1.171710e+06</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1.238298e+06</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>4.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.345435e+07</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>4.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Sample_code_number  Clump_Thickness  Uniformity_of_Cell_Size  \\\n",
       "count        6.990000e+02       699.000000               699.000000   \n",
       "mean         1.071704e+06         4.417740                 3.134478   \n",
       "std          6.170957e+05         2.815741                 3.051459   \n",
       "min          6.163400e+04         1.000000                 1.000000   \n",
       "25%          8.706885e+05         2.000000                 1.000000   \n",
       "50%          1.171710e+06         4.000000                 1.000000   \n",
       "75%          1.238298e+06         6.000000                 5.000000   \n",
       "max          1.345435e+07        10.000000                10.000000   \n",
       "\n",
       "       Uniformity_of_Cell_Shape  Marginal_Adhesion  \\\n",
       "count                699.000000         699.000000   \n",
       "mean                   3.207439           2.806867   \n",
       "std                    2.971913           2.855379   \n",
       "min                    1.000000           1.000000   \n",
       "25%                    1.000000           1.000000   \n",
       "50%                    1.000000           1.000000   \n",
       "75%                    5.000000           4.000000   \n",
       "max                   10.000000          10.000000   \n",
       "\n",
       "       Single_Epithelial_Cell_Size  Bland_Chromatin  Normal_Nucleoli  \\\n",
       "count                   699.000000       699.000000       699.000000   \n",
       "mean                      3.216023         3.437768         2.866953   \n",
       "std                       2.214300         2.438364         3.053634   \n",
       "min                       1.000000         1.000000         1.000000   \n",
       "25%                       2.000000         2.000000         1.000000   \n",
       "50%                       2.000000         3.000000         1.000000   \n",
       "75%                       4.000000         5.000000         4.000000   \n",
       "max                      10.000000        10.000000        10.000000   \n",
       "\n",
       "          Mitoses       Class  \n",
       "count  699.000000  699.000000  \n",
       "mean     1.589413    2.689557  \n",
       "std      1.715078    0.951273  \n",
       "min      1.000000    2.000000  \n",
       "25%      1.000000    2.000000  \n",
       "50%      1.000000    2.000000  \n",
       "75%      1.000000    4.000000  \n",
       "max     10.000000    4.000000  "
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bc.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sample_code_number</th>\n",
       "      <th>Clump_Thickness</th>\n",
       "      <th>Uniformity_of_Cell_Size</th>\n",
       "      <th>Uniformity_of_Cell_Shape</th>\n",
       "      <th>Marginal_Adhesion</th>\n",
       "      <th>Single_Epithelial_Cell_Size</th>\n",
       "      <th>Bare_Nuclei</th>\n",
       "      <th>Bland_Chromatin</th>\n",
       "      <th>Normal_Nucleoli</th>\n",
       "      <th>Mitoses</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1000025</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1002945</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "      <td>10</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1015425</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1016277</td>\n",
       "      <td>6</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1017023</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Sample_code_number  Clump_Thickness  Uniformity_of_Cell_Size  \\\n",
       "0             1000025                5                        1   \n",
       "1             1002945                5                        4   \n",
       "2             1015425                3                        1   \n",
       "3             1016277                6                        8   \n",
       "4             1017023                4                        1   \n",
       "\n",
       "   Uniformity_of_Cell_Shape  Marginal_Adhesion  Single_Epithelial_Cell_Size  \\\n",
       "0                         1                  1                            2   \n",
       "1                         4                  5                            7   \n",
       "2                         1                  1                            2   \n",
       "3                         8                  1                            3   \n",
       "4                         1                  3                            2   \n",
       "\n",
       "  Bare_Nuclei  Bland_Chromatin  Normal_Nucleoli  Mitoses  Class  \n",
       "0           1                3                1        1      2  \n",
       "1          10                3                2        1      2  \n",
       "2           2                3                1        1      2  \n",
       "3           4                3                7        1      2  \n",
       "4           1                3                1        1      2  "
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bc.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample_code_number   int64\n",
      "Clump_Thickness   int64\n",
      "Uniformity_of_Cell_Size   int64\n",
      "Uniformity_of_Cell_Shape   int64\n",
      "Marginal_Adhesion   int64\n",
      "Single_Epithelial_Cell_Size   int64\n",
      "Bare_Nuclei   object\n",
      "Bland_Chromatin   int64\n",
      "Normal_Nucleoli   int64\n",
      "Mitoses   int64\n",
      "Class   int64\n",
      "Sample_code_number             16\n",
      "Clump_Thickness                16\n",
      "Uniformity_of_Cell_Size        16\n",
      "Uniformity_of_Cell_Shape       16\n",
      "Marginal_Adhesion              16\n",
      "Single_Epithelial_Cell_Size    16\n",
      "Bare_Nuclei                    16\n",
      "Bland_Chromatin                16\n",
      "Normal_Nucleoli                16\n",
      "Mitoses                        16\n",
      "Class                          16\n",
      "dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(683, 11)"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for col in bc.columns:\n",
    "    print(col ,\" \", bc[col].dtype)\n",
    "print(bc[bc['Bare_Nuclei']=='?'].count())\n",
    "\n",
    "#since there are only 16 rows where there are question marks I am deleting those rows from the dataset\n",
    "bc = bc[bc.Bare_Nuclei != \"?\"]\n",
    "bc.shape\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.b: Model Building\n",
    "\n",
    "- What's the baseline for the accuracy?\n",
    "- Initialize and train a linear svm. What's the average accuracy score with a 3-fold cross validation?\n",
    "- Repeat using an rbf classifier. Compare the scores. Which one is better?\n",
    "- Are your features normalized? if not, try normalizing and repeat the test. Does the score improve?\n",
    "- What's the best model?\n",
    "- Print a confusion matrix and classification report for your best model using:\n",
    "        train_test_split(X, y, stratify=y, test_size=0.33, random_state=42)\n",
    "\n",
    "**Check** to decide which model is best, look at the average cross validation score. Are the scores significantly different from one another?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(683,)"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = bc.drop(['Sample_code_number', 'Class'], axis = 1)\n",
    "y = bc['Class'] == 4\n",
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False    444\n",
      "True     239\n",
      "Name: Class, dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "False    0.650073\n",
       "True     0.349927\n",
       "Name: Class, dtype: float64"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print (y.value_counts())\n",
    "#baseline => 65%\n",
    "y.value_counts() / len(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
      "  decision_function_shape=None, degree=3, gamma='auto', kernel='linear',\n",
      "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
      "  tol=0.001, verbose=False)\n",
      "Average score: 0.965+/-0.0179\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.cross_validation import cross_val_score\n",
    "\n",
    "all_scores = []\n",
    "model = SVC(kernel='linear')\n",
    "\n",
    "def do_cv(model, X, y, cv):\n",
    "    scores = cross_val_score(model, X, y, cv=cv)\n",
    "    print (model)\n",
    "    sm = scores.mean()\n",
    "    ss = scores.std()\n",
    "    res = (sm, ss)\n",
    "    print (\"Average score: {:0.3}+/-{:0.3}\".format(*res))\n",
    "    return res\n",
    "\n",
    "all_scores.append(do_cv(model, X, y, 3))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
      "  decision_function_shape=None, degree=3, gamma='auto', kernel='rbf',\n",
      "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
      "  tol=0.001, verbose=False)\n",
      "Average score: 0.958+/-0.0251\n"
     ]
    }
   ],
   "source": [
    "model = SVC(kernel='rbf')\n",
    "all_scores.append(do_cv(model, X, y, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline(steps=[('standardscaler', StandardScaler(copy=True, with_mean=True, with_std=True)), ('svc', SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
      "  decision_function_shape=None, degree=3, gamma='auto', kernel='linear',\n",
      "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
      "  tol=0.001, verbose=False))])\n",
      "Average score: 0.966+/-0.0161\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import make_pipeline\n",
    "\n",
    "model = make_pipeline(StandardScaler(), SVC(kernel='linear'))\n",
    "all_scores.append(do_cv(model, X, y, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline(steps=[('standardscaler', StandardScaler(copy=True, with_mean=True, with_std=True)), ('svc', SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
      "  decision_function_shape=None, degree=3, gamma='auto', kernel='rbf',\n",
      "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
      "  tol=0.001, verbose=False))])\n",
      "Average score: 0.968+/-0.018\n"
     ]
    }
   ],
   "source": [
    "model = make_pipeline(StandardScaler(), SVC(kernel='rbf'))\n",
    "all_scores.append(do_cv(model, X, y, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "\n",
    "def print_cm_cr(y_true, y_pred, names):\n",
    "    \"\"\"prints the confusion matrix and the classification report\"\"\"\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    cols = ['pred_' + c for c in names]\n",
    "    dfcm = pd.DataFrame(cm, columns = cols, index = names)\n",
    "    print (dfcm)\n",
    "    print ()\n",
    "    print (classification_report(y_true, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.cross_validation import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = make_pipeline(StandardScaler(), SVC(kernel='rbf'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Check:** Are there more false positives or false negatives? Is this good or bad?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.c: Feature Selection\n",
    "\n",
    "Use any of the strategies offered by `sklearn` to select the most important features.\n",
    "\n",
    "Repeat the cross validation with only those 5 features. Does the score change?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.d: Learning Curves\n",
    "\n",
    "Learning curves are useful to study the behavior of training and test errors as a function of the number of datapoints available.\n",
    "\n",
    "- Plot learning curves for train sizes between 10% and 100% (use StratifiedKFold with 5 folds as cross validation)\n",
    "- What can you say about the dataset? do you need more data or do you need a better model?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  1.e: Grid Ssearch\n",
    "\n",
    "Use the grid_search function to explore different kernels and values for the C parameter.\n",
    "\n",
    "- Can you improve on your best previous score?\n",
    "- Print the best parameters and the best score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 2\n",
    "Now that you've completed steps 1.a through 1.e it's time to tackle some harder datasets. But before we do that, let's encapsulate a few things into functions so that it's easier to repeat the analysis.\n",
    "\n",
    "## 2.a: Cross Validation\n",
    "Implement a function `do_cv(model, X, y, cv)` that does the following:\n",
    "- Calculates the cross validation scores\n",
    "- Prints the model\n",
    "- Prints and returns the mean and the standard deviation of the cross validation scores\n",
    "\n",
    "> Answer: see above\n",
    "\n",
    "## 2.b: Confusion Matrix and Classification report\n",
    "Implement a function `do_cm_cr(model, X, y, names)` that automates the following:\n",
    "- Split the data using `train_test_split(X, y, stratify=y, test_size=0.33, random_state=42)`\n",
    "- Fit the model\n",
    "- Prints confusion matrix and classification report in a nice format\n",
    "\n",
    "**Hint:** names is the list of target classes\n",
    "\n",
    "> Answer: see above\n",
    "\n",
    "## 2.c: Learning Curves\n",
    "Implement a function `do_learning_curve(model, X, y, sizes)` that automates drawing the learning curves:\n",
    "- Allow for sizes input\n",
    "- Use 5-fold StratifiedKFold cross validation\n",
    "\n",
    "> Answer: see above\n",
    "\n",
    "## 2.d: Grid Search\n",
    "Implement a function `do_grid_search(model, parameters)` that automates the grid search by doing:\n",
    "- Calculate grid search\n",
    "- Print best parameters\n",
    "- Print best score\n",
    "- Return best estimator\n",
    "\n",
    "\n",
    "> Answer: see above"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 3\n",
    "Using the functions above, analyze the Spambase dataset.\n",
    "\n",
    "Notice that now you have many more features. Focus your attention on step C => feature selection\n",
    "\n",
    "- Load the data and get to X, y\n",
    "- Select the 15 best features\n",
    "- Perform grid search to determine best model\n",
    "- Display learning curves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 4\n",
    "Repeat steps 1.a - 1.e for the car dataset. Notice that now features are categorical, not numerical.\n",
    "- Find a suitable way to encode them\n",
    "- How does this change our modeling strategy?\n",
    "\n",
    "Also notice that the target variable `acceptability` has 4 classes. How do we encode them?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bonus\n",
    "Repeat steps 1.a - 1.e for the mushroom dataset. Notice that now features are categorical, not numerical. This dataset is quite large.\n",
    "- How does this change our modeling strategy?\n",
    "- Can we use feature selection to improve this?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
